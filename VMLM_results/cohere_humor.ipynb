{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/debajyoti/test/llms/envllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,TrainingArguments\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# you may want to change the following parameters depending on your GPU configuration\n",
    "\n",
    "# free T4 instance\n",
    "# QUANTIZE_4BIT = True\n",
    "# USE_GRAD_CHECKPOINTING = True\n",
    "# TRAIN_BATCH_SIZE = 2\n",
    "# TRAIN_MAX_SEQ_LENGTH = 512\n",
    "# USE_FLASH_ATTENTION = False\n",
    "# GRAD_ACC_STEPS = 16\n",
    "\n",
    "# equivalent A100 setting\n",
    "QUANTIZE_4BIT = True\n",
    "USE_GRAD_CHECKPOINTING = True\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TRAIN_MAX_SEQ_LENGTH = 512\n",
    "USE_FLASH_ATTENTION = True\n",
    "GRAD_ACC_STEPS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.31s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"CohereForAI/aya-expanse-8b\"\n",
    "models_path = \"/data1/debajyoti/test/llms/models/\"\n",
    "\n",
    "attn_implementation = None\n",
    "if USE_FLASH_ATTENTION:\n",
    "  attn_implementation=\"flash_attention_2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          MODEL_NAME,\n",
    "          attn_implementation=attn_implementation,\n",
    "          torch_dtype=torch.bfloat16,\n",
    "          cache_dir=models_path,\n",
    "          device_map=\"auto\"\n",
    "        )\n",
    "# model = model.to(device)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_format(prompts):\n",
    "  messages = []\n",
    "\n",
    "  for p in prompts:\n",
    "    messages.append(\n",
    "          [{\"role\": \"system\", \"content\": \"\"\"You are a humor recognition assistant judging if an 'Input' is humorous or not. No need to consider any prior context.\n",
    "            If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \n",
    "            If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"\"\"},\n",
    "          {\"role\": \"user\", \"content\": p}]\n",
    "      )\n",
    "\n",
    "  return messages\n",
    "\n",
    "def generate_aya(\n",
    "      model,\n",
    "      prompts,\n",
    "      temperature=0.75,\n",
    "      top_p=1.0,\n",
    "      top_k=0,\n",
    "      max_new_tokens=1024\n",
    "    ):\n",
    "\n",
    "  # print(prompts)\n",
    "  messages = get_message_format(prompts)\n",
    "  # print(messages)\n",
    "\n",
    "  input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "      )\n",
    "  input_ids = input_ids.to(model.device)\n",
    "  prompt_padded_len = len(input_ids[0])\n",
    "\n",
    "  gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "      )\n",
    "\n",
    "  # get only generated tokens\n",
    "  gen_tokens = [\n",
    "      gt[prompt_padded_len:] for gt in gen_tokens\n",
    "    ]\n",
    "\n",
    "  gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "  return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Input: \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi\" \n",
      "    Output: \n",
      "RESPONSE\n",
      "Output: Humor\n",
      "\n",
      "The statement plays on the idea of a hypothetical situation where the Vice President's actions or decisions might have been different if they were not Muslim, suggesting a subtle critique of religious biases. The use of \"chalo\" (let's) and the casual tone add to the humorous effect, making it a witty observation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test generations on langauges in Aya 23 set\n",
    "prompts = [\n",
    "    \"\"\"Input: \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi\" \n",
    "    Output: \"\"\"\n",
    "]\n",
    "\n",
    "generations = generate_aya(model, prompts)\n",
    "\n",
    "for p, g in zip(prompts, generations):\n",
    "  print(\n",
    "      \"PROMPT\", p ,\"RESPONSE\", g, \"\\n\", sep=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 2 takiye ki naukri main mera lakhon ka worl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Naam : Viv Richards\\nBaap ka naam : Master Di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sakshi Maharaj is BJP's Digvijaya Singh.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj @British_Airways ki toh lag gayi bhai.\\nHa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghanta development hoga! Saare paise to electi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hum to Aam Aadmi hain ji, woh Megalomaniac hai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Neend nahi aati hai raaton mein?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Ghar mein Bipasha Basu ki photo rakhne se bhoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tu na ja mere baadshah ek waade ke liye, maa c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Tag\n",
       "0    Is 2 takiye ki naukri main mera lakhon ka worl...    0\n",
       "1    \"Naam : Viv Richards\\nBaap ka naam : Master Di...    1\n",
       "2             Sakshi Maharaj is BJP's Digvijaya Singh.    1\n",
       "3    Aaj @British_Airways ki toh lag gayi bhai.\\nHa...    1\n",
       "4    Ghanta development hoga! Saare paise to electi...    1\n",
       "..                                                 ...  ...\n",
       "291  Hum to Aam Aadmi hain ji, woh Megalomaniac hai...    1\n",
       "292                   Neend nahi aati hai raaton mein?    0\n",
       "293  Ghar mein Bipasha Basu ki photo rakhne se bhoo...    1\n",
       "294    Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V    0\n",
       "295  Tu na ja mere baadshah ek waade ke liye, maa c...    1\n",
       "\n",
       "[296 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_eng = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Humour_English(NEW).csv\")\n",
    "# train_df_eng = train_df_eng[:2000]\n",
    "# train_df_hin = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Humour_English(NEW).csv\")\n",
    "# train_df_hin = train_df_hin[:2000]\n",
    "# train_df = pd.concat([train_df_eng, train_df_hin], ignore_index=True)\n",
    "# train_df = train_df_hin\n",
    "train_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/train.csv\")\n",
    "val_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/val.csv\")\n",
    "test_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/test.csv\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>दिमाग पैराशूट की तरह हैं।वे खुले होने पर सबसे ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>राजकुमारी, राजकुमारों के साथ पर्याप्त अनुभव था...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>यदि यह पर्यटक का मौसम है, तो मुझे लाइसेंस कहां...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>यदि कोई जॉगर ध्वनि की गति से चलता है, तो क्या ...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>जब आपका जीवन एक लाख टुकड़ों में बिखर जाता है, ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>मेरी प्रेमिका ने सोचा कि यह सिर्फ एक मसौदा है,...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>आपने मुझे किसी ऐसे व्यक्ति के लिए गलत किया है ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>बस जब मैं सिरों को पूरा करता हूं, तो कोई छोर ल...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Tag\n",
       "0  दिमाग पैराशूट की तरह हैं।वे खुले होने पर सबसे ...      Humor\n",
       "1  राजकुमारी, राजकुमारों के साथ पर्याप्त अनुभव था...  Non-humor\n",
       "2  यदि यह पर्यटक का मौसम है, तो मुझे लाइसेंस कहां...      Humor\n",
       "3  यदि कोई जॉगर ध्वनि की गति से चलता है, तो क्या ...  Non-humor\n",
       "4  जब आपका जीवन एक लाख टुकड़ों में बिखर जाता है, ...      Humor\n",
       "5  मेरी प्रेमिका ने सोचा कि यह सिर्फ एक मसौदा है,...  Non-humor\n",
       "6  आपने मुझे किसी ऐसे व्यक्ति के लिए गलत किया है ...      Humor\n",
       "7  बस जब मैं सिरों को पूरा करता हूं, तो कोई छोर ल...  Non-humor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/humor/few_shots/16000_hin_eng.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'दिमाग पैराशूट की तरह हैं।वे खुले होने पर सबसे अच्छा काम करते हैं।बस सुनिश्चित करें कि तार अभी भी संलग्न हैं।'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'राजकुमारी, राजकुमारों के साथ पर्याप्त अनुभव था, मेंढक की तलाश करता है।'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'यदि यह पर्यटक का मौसम है, तो मुझे लाइसेंस कहां मिलेगा?'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'यदि कोई जॉगर ध्वनि की गति से चलता है, तो क्या वह अभी भी अपने वॉकमैन को सुन सकता है?'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'जब आपका जीवन एक लाख टुकड़ों में बिखर जाता है, तो टुकड़ों को उठाएं, कुछ गोंद को पकड़ें, और एक नया बनाएं।'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'मेरी प्रेमिका ने सोचा कि यह सिर्फ एक मसौदा है, इसलिए उसने किनारों को स्कैलप किया और इसे कपकेक लाइनर के लिए इस्तेमाल किया।'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'आपने मुझे किसी ऐसे व्यक्ति के लिए गलत किया है जो लानत देता है।'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'बस जब मैं सिरों को पूरा करता हूं, तो कोई छोर ले जाता है।'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to specified format\n",
    "formatted_few_shot_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted_few_shot_examples.append({'role': 'user', 'content': row['Sentence']})\n",
    "    formatted_few_shot_examples.append({'role': 'assistant', 'content': row['Tag']})\n",
    "    \n",
    "formatted_few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input': \"दिमाग पैराशूट की तरह हैं।वे खुले होने पर सबसे अच्छा काम करते हैं।बस सुनिश्चित करें कि तार अभी भी संलग्न हैं।\"\n",
      "'Response':\"Humor\"\n",
      "\n",
      "'Input': \"राजकुमारी, राजकुमारों के साथ पर्याप्त अनुभव था, मेंढक की तलाश करता है।\"\n",
      "'Response':\"Non-humor\"\n",
      "\n",
      "'Input': \"यदि यह पर्यटक का मौसम है, तो मुझे लाइसेंस कहां मिलेगा?\"\n",
      "'Response':\"Humor\"\n",
      "\n",
      "'Input': \"यदि कोई जॉगर ध्वनि की गति से चलता है, तो क्या वह अभी भी अपने वॉकमैन को सुन सकता है?\"\n",
      "'Response':\"Non-humor\"\n",
      "\n",
      "'Input': \"जब आपका जीवन एक लाख टुकड़ों में बिखर जाता है, तो टुकड़ों को उठाएं, कुछ गोंद को पकड़ें, और एक नया बनाएं।\"\n",
      "'Response':\"Humor\"\n",
      "\n",
      "'Input': \"मेरी प्रेमिका ने सोचा कि यह सिर्फ एक मसौदा है, इसलिए उसने किनारों को स्कैलप किया और इसे कपकेक लाइनर के लिए इस्तेमाल किया।\"\n",
      "'Response':\"Non-humor\"\n",
      "\n",
      "'Input': \"आपने मुझे किसी ऐसे व्यक्ति के लिए गलत किया है जो लानत देता है।\"\n",
      "'Response':\"Humor\"\n",
      "\n",
      "'Input': \"बस जब मैं सिरों को पूरा करता हूं, तो कोई छोर ले जाता है।\"\n",
      "'Response':\"Non-humor\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_few_shot_examples = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    # if index == 3: # or index == 4:\n",
    "    #     formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    # if index == 1:\n",
    "    #     break\n",
    "\n",
    "# Display the result\n",
    "print(formatted_few_shot_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt, parse response and  generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the function to create the prompt\n",
    "def create_prompt(input, num_examples):\n",
    "\n",
    "    # System prompt \n",
    "    # system_prompt = \"\"\"You are a humor recognition assistant judging if an 'Input' is humor or not. \n",
    "    #     If the 'Input' is humorous, you need to give your final 'Output' as \"Humor\". \n",
    "    #     If the 'Input' is non-humorous, you need to give your final 'Output' as \"Non-humor\". Dont output anything else. \"\"\"\n",
    "\n",
    "    # messages = [system_prompt + formatted_few_shot_examples, f\"\\'Input\\':'{input}'\\n\\'Response\\':\"]\n",
    "    messages = f\"\"\"\n",
    "                {formatted_few_shot_examples}\n",
    "                \\'Input\\':'{input}'\n",
    "                \\'Response\\':\n",
    "    \"\"\"\n",
    "    # messages = [system_prompt, input]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def parse_response(response):\n",
    "    \"\"\"\n",
    "    Extracts the classification label and explanation from the model-generated response,\n",
    "    starting from the line containing the final \"Answer:\".\n",
    "\n",
    "    Args:\n",
    "        response (str): The response generated by the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the classification label (\"Humor\" or \"Non-humor\") \n",
    "               and the explanation text.\n",
    "    \"\"\"\n",
    "    # print(response)\n",
    "    if len(response) > 0:        \n",
    "        if \"Non-humor\" in response:\n",
    "            return \"0\"\n",
    "        elif \"Humor\" in response:\n",
    "            return \"1\"\n",
    "        else:# If no label is found, return None\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 296/296 [21:28<00:00,  4.35s/it]\n"
     ]
    }
   ],
   "source": [
    "def process_data(output_filepath):\n",
    "    # df = pd.read_csv(data_filepath)\n",
    "    df = test_df\n",
    "    # print(df)\n",
    "    # df = df[:5]\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    num_examples = 15 # number of shots in few-shot\n",
    "    # Loop over the DataFrame and pass the text to generate response\n",
    "    for index, row in tqdm(list(df.iterrows())):\n",
    "        # print(row)\n",
    "        prompt = create_prompt(row['Sentence'], num_examples)\n",
    "        # print(prompt)\n",
    "        generations = generate_aya(model, [prompt])\n",
    "        # print(generations[0])\n",
    "        generated_label = parse_response(generations[0])\n",
    "        # print(generated_label)\n",
    "\n",
    "        # # veracity, explanation = parse_response(model_response)\n",
    "        \n",
    "        results.append({\n",
    "            'Sentence': row['Sentence'],\n",
    "            'Label': row['Tag'],\n",
    "            'Response': generations[0],\n",
    "            'Gen_label': generated_label,\n",
    "            # 'Explanation': explanation\n",
    "        })\n",
    "        # break\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example file paths, replace with your actual paths\n",
    "output_filepath = '/data1/debajyoti/test/llms/data/humor'\n",
    "\n",
    "# Run the data processing\n",
    "result = process_data(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gen_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 2 takiye ki naukri main mera lakhon ka worl...</td>\n",
       "      <td>0</td>\n",
       "      <td>'Humor'\\n\\nयह वाक्य एक हास्यप्रद तुलना प्रस्तु...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Naam : Viv Richards\\nBaap ka naam : Master Di...</td>\n",
       "      <td>1</td>\n",
       "      <td>'Response': \"Non-humor\"\\n\\nयह इनपुट एक व्यक्ति...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sakshi Maharaj is BJP's Digvijaya Singh.</td>\n",
       "      <td>1</td>\n",
       "      <td>'Non-humor'\\n\\nदिए गए इनपुट में कोई हास्यास्पद...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj @British_Airways ki toh lag gayi bhai.\\nHa...</td>\n",
       "      <td>1</td>\n",
       "      <td>'Humor'\\n\\nइस इनपुट में एक हल्के-फुल्के और मजा...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghanta development hoga! Saare paise to electi...</td>\n",
       "      <td>1</td>\n",
       "      <td>'Humor'\\n\\nयह वाक्यांश व्यंग्यात्मक और हास्यप्...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hum to Aam Aadmi hain ji, woh Megalomaniac hai...</td>\n",
       "      <td>1</td>\n",
       "      <td>'Humor'\\n\\nयह इनपुट में एक व्यंग्यात्मक और हास...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Neend nahi aati hai raaton mein?</td>\n",
       "      <td>0</td>\n",
       "      <td>'Humor'\\n\\nयह वाक्यांश एक आम समस्या को हास्यपू...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Ghar mein Bipasha Basu ki photo rakhne se bhoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>'Humor'\\n\\nयह वाक्य एक हास्यप्रद छवि पेश करता ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V</td>\n",
       "      <td>0</td>\n",
       "      <td>'Non-humor'\\n\\nइस इनपुट में कोई हास्यप्रद तत्व...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tu na ja mere baadshah ek waade ke liye, maa c...</td>\n",
       "      <td>1</td>\n",
       "      <td>'Humor'\\n\\nयह वाक्यांश एक हास्यप्रद और संगीतमय...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Label  \\\n",
       "0    Is 2 takiye ki naukri main mera lakhon ka worl...      0   \n",
       "1    \"Naam : Viv Richards\\nBaap ka naam : Master Di...      1   \n",
       "2             Sakshi Maharaj is BJP's Digvijaya Singh.      1   \n",
       "3    Aaj @British_Airways ki toh lag gayi bhai.\\nHa...      1   \n",
       "4    Ghanta development hoga! Saare paise to electi...      1   \n",
       "..                                                 ...    ...   \n",
       "291  Hum to Aam Aadmi hain ji, woh Megalomaniac hai...      1   \n",
       "292                   Neend nahi aati hai raaton mein?      0   \n",
       "293  Ghar mein Bipasha Basu ki photo rakhne se bhoo...      1   \n",
       "294    Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V      0   \n",
       "295  Tu na ja mere baadshah ek waade ke liye, maa c...      1   \n",
       "\n",
       "                                              Response Gen_label  \n",
       "0    'Humor'\\n\\nयह वाक्य एक हास्यप्रद तुलना प्रस्तु...         1  \n",
       "1    'Response': \"Non-humor\"\\n\\nयह इनपुट एक व्यक्ति...         0  \n",
       "2    'Non-humor'\\n\\nदिए गए इनपुट में कोई हास्यास्पद...         0  \n",
       "3    'Humor'\\n\\nइस इनपुट में एक हल्के-फुल्के और मजा...         1  \n",
       "4    'Humor'\\n\\nयह वाक्यांश व्यंग्यात्मक और हास्यप्...         1  \n",
       "..                                                 ...       ...  \n",
       "291  'Humor'\\n\\nयह इनपुट में एक व्यंग्यात्मक और हास...         1  \n",
       "292  'Humor'\\n\\nयह वाक्यांश एक आम समस्या को हास्यपू...         1  \n",
       "293  'Humor'\\n\\nयह वाक्य एक हास्यप्रद छवि पेश करता ...         1  \n",
       "294  'Non-humor'\\n\\nइस इनपुट में कोई हास्यप्रद तत्व...         0  \n",
       "295  'Humor'\\n\\nयह वाक्यांश एक हास्यप्रद और संगीतमय...         1  \n",
       "\n",
       "[296 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
