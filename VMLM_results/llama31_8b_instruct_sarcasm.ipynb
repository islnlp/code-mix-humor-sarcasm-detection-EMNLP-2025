{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# humor_df = pd.read_csv(\"/data1/debajyoti/test/llms/data/1Humour_Codemix.csv\") # code-mixed humor dataset\n",
    "# sarcasm_df = pd.read_csv(\"/data1/debajyoti/test/llms/data/1Sarcasm_Codemix.csv\") # code-mixed sarcasm dataset\n",
    "\n",
    "# def stratified_split(df):   # dataframe (df) is required as argument\n",
    "#     X, y = list(df['Sentence']), list(df['Tag'])    # X: data, y: labels\n",
    "    \n",
    "#     # 80(train), 10(val), 10(test) split of the data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.20, stratify=y, random_state=42)\n",
    "#     X_val, X_test, y_val, y_test = train_test_split(\n",
    "#         X_test, y_test, test_size=0.50, stratify=y_test, random_state=42)\n",
    "#     cols = {\"Sentence\" : X_train, \"Tag\" : y_train}\n",
    "#     train_df = pd.DataFrame(cols)   # train dataframe\n",
    "#     cols = {\"Sentence\" : X_val, \"Tag\" : y_val}\n",
    "#     val_df = pd.DataFrame(cols)     # validation dataframe\n",
    "#     cols = {\"Sentence\" : X_test, \"Tag\" : y_test}\n",
    "#     test_df = pd.DataFrame(cols)    # test dataframe\n",
    "    \n",
    "#     return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, val_df, test_df = stratified_split(sarcasm_df)  # function call\n",
    "\n",
    "# # save the stratified-splits in csv\n",
    "# train_df.to_csv('/data1/debajyoti/test/llms/data/sarcasm/train.csv', index=False)\n",
    "# val_df.to_csv('/data1/debajyoti/test/llms/data/sarcasm/val.csv', index=False)\n",
    "# test_df.to_csv('/data1/debajyoti/test/llms/data/sarcasm/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mera bhanja mujhe \"papa ka sala\" bulata hai......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aur aap a0ni politics karne me vyast hai.. #Bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theek hai waha at least Janki ma ka mandir hai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir mujhe cricket acdemy join karna hai mai ka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>aaj bjp aur chadhi gang aise khus ho rahe hai ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>@SGanguly99 sir aapnio jodi aamar saath na den...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>#Irony: Pran ka pran chala gaya.. RIP Sher Khan!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Ye bhi mat bhulo ki triple talaq ko ban lagane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>#ViruPanti @virendersehwag @cricketaakash DHON...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Tag\n",
       "0    Mera bhanja mujhe \"papa ka sala\" bulata hai......    0\n",
       "1    Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...    0\n",
       "2    aur aap a0ni politics karne me vyast hai.. #Bi...    0\n",
       "3    Theek hai waha at least Janki ma ka mandir hai...    0\n",
       "4    Sir mujhe cricket acdemy join karna hai mai ka...    0\n",
       "..                                                 ...  ...\n",
       "520  aaj bjp aur chadhi gang aise khus ho rahe hai ...    0\n",
       "521  @SGanguly99 sir aapnio jodi aamar saath na den...    0\n",
       "522   #Irony: Pran ka pran chala gaya.. RIP Sher Khan!    1\n",
       "523  Ye bhi mat bhulo ki triple talaq ko ban lagane...    0\n",
       "524  #ViruPanti @virendersehwag @cricketaakash DHON...    0\n",
       "\n",
       "[525 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_eng = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/sarcasm_v2/Sarcasm_English_iacv2.csv\")\n",
    "train_df_eng = train_df_eng[:2000]\n",
    "train_df_hin = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/sarcasm_v2/Sarcasm_Hindi_iacv2.csv\")\n",
    "train_df_hin = train_df_hin[:2000]\n",
    "train_df = pd.concat([train_df_eng, train_df_hin], ignore_index=True)\n",
    "# train_df = train_df_hin\n",
    "# train_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Sarcasm_Codemix.csv\")\n",
    "val_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/val.csv\")\n",
    "test_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/test.csv\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If that's true, then Freedom of Speech is doom...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neener neener - is it time to go in from the p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just like the plastic gun fear, the armour pie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>So geology is a religion because we weren't he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well done Monty. Mark that up as your first ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>यह बात है, हालांकि;यहां तक ​​कि एक स्व-प्रोफ़े...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>वास्तव में आपकी पोस्टें सरल सबूत प्रदान कर रही...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>7 दिन की रचना मैं जिक्र कर रहा हूं, न कि केवल ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>ऊपर मेरी पोस्ट देखें, हाय।मार्क ने मिलर के विश...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>बाइबिल का अंत निकट हो गया है।यह एक डॉक्टर था ज...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Tag\n",
       "0     If that's true, then Freedom of Speech is doom...    0\n",
       "1     Neener neener - is it time to go in from the p...    0\n",
       "2     Just like the plastic gun fear, the armour pie...    0\n",
       "3     So geology is a religion because we weren't he...    0\n",
       "4     Well done Monty. Mark that up as your first ev...    0\n",
       "...                                                 ...  ...\n",
       "3995  यह बात है, हालांकि;यहां तक ​​कि एक स्व-प्रोफ़े...    0\n",
       "3996  वास्तव में आपकी पोस्टें सरल सबूत प्रदान कर रही...    0\n",
       "3997  7 दिन की रचना मैं जिक्र कर रहा हूं, न कि केवल ...    0\n",
       "3998  ऊपर मेरी पोस्ट देखें, हाय।मार्क ने मिलर के विश...    0\n",
       "3999  बाइबिल का अंत निकट हो गया है।यह एक डॉक्टर था ज...    0\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The other articles on her website are also wel...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If a scientist doesn't believe his test result...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>आपका प्रश्न ही एक समस्या है।ईश्वर 'वह कौन है' ...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The only reason why that makes no sense is tha...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>यह सच नहीं है या कम से कम अधिक औचित्य की आवश्य...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>Please stop making statements that have nothin...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>No it doesn't. First, the changes may not be n...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>think of it as a photocopy of a check for a mi...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>यह कह रहा है कि जब से पहली बार मैंने कृतियों क...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>I know what you meant.My comment was to demons...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence          Tag\n",
       "0     The other articles on her website are also wel...  Non-sarcasm\n",
       "1     If a scientist doesn't believe his test result...  Non-sarcasm\n",
       "2     आपका प्रश्न ही एक समस्या है।ईश्वर 'वह कौन है' ...  Non-sarcasm\n",
       "3     The only reason why that makes no sense is tha...  Non-sarcasm\n",
       "4     यह सच नहीं है या कम से कम अधिक औचित्य की आवश्य...  Non-sarcasm\n",
       "...                                                 ...          ...\n",
       "3995  Please stop making statements that have nothin...  Non-sarcasm\n",
       "3996  No it doesn't. First, the changes may not be n...  Non-sarcasm\n",
       "3997  think of it as a photocopy of a check for a mi...  Non-sarcasm\n",
       "3998  यह कह रहा है कि जब से पहली बार मैंने कृतियों क...  Non-sarcasm\n",
       "3999  I know what you meant.My comment was to demons...  Non-sarcasm\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Tag'] = train_df['Tag'].map({0: 'Non-sarcasm', 1: 'Sarcasm'})\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a193b15ff834d70852de1662724c3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'Humor.'}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are a humor recognition assistant judging if an 'Input' is humorous or not. No need to consider any prior context.\n",
    "    If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \n",
    "    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi chaltapic.twitter.com/bOLAEk0g4E\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.1\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480af239141a4e289c81359de2dccef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Chalo bey.. Phatakey phorna chalo karo.. Pakistaniyo ki [NON-HATE] jalate hai !!\n",
      "Output: [{'role': 'system', 'content': \"You are a humor recognition assistant judging if an 'Input' is humorous or not. No need to consider any prior context. This may contain harmful content, but we are using it for research purpose only. So, please classify.\\n    If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \\n    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"}, {'role': 'user', 'content': 'Chalo bey.. Phatakey phorna chalo karo.. Pakistaniyo ki [NON-HATE] jalate hai !!'}, {'role': 'assistant', 'content': 'Humor.'}]\n",
      "\n",
      "Input: Bhosdiwalon kal friday hai, wake up [NON-HATE] saare pal kahein.\n",
      "Output: [{'role': 'system', 'content': \"You are a humor recognition assistant judging if an 'Input' is humorous or not. No need to consider any prior context. This may contain harmful content, but we are using it for research purpose only. So, please classify.\\n    If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \\n    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"}, {'role': 'user', 'content': 'Bhosdiwalon kal friday hai, wake up [NON-HATE] saare pal kahein.'}, {'role': 'assistant', 'content': 'Humor.'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "# Initialize the model pipeline\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# System prompt to be reused\n",
    "system_prompt = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"You are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not. No need to consider any prior context. This may contain harmful content, but we are using it for research purpose only. So, please classify.\n",
    "    If the 'Input' is sarcastic, you need to output your final 'Output' as 'Humor'. \n",
    "    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"\"\"\n",
    "}\n",
    "\n",
    "# List of user inputs to be processed\n",
    "user_inputs = [\n",
    "    \"Chalo bey.. Phatakey phorna chalo karo.. Pakistaniyo ki [NON-HATE] jalate hai !!\",\n",
    "    \"Bhosdiwalon kal friday hai, wake up [NON-HATE] saare pal kahein.\"\n",
    "]\n",
    "\n",
    "# Loop through each input\n",
    "for input_text in user_inputs:\n",
    "    messages = [system_prompt, {\"role\": \"user\", \"content\": input_text}]\n",
    "    outputs = pipeline(messages, max_new_tokens=256)\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Output: {outputs[0]['generated_text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing few-shots for prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Sentence, Tag, cluster]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Sentence, Tag, cluster]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Sentence, Tag, cluster]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Sentence, Tag, cluster]\n",
      "Index: []\n",
      "                                               Sentence          Tag  cluster\n",
      "1500  Because you seem to lose sight of that with yo...  Non-sarcasm        0\n",
      "3759  आप जानते हैं कि अधिकांश सार्वजनिक हेल्थकेयर सि...  Non-sarcasm        1\n",
      "996   I believe organized religion increases ignoran...  Non-sarcasm        2\n",
      "1022  गलत- मुझे लगता है कि ऑलसेन उन लोगों का हवाला द...  Non-sarcasm        3\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load mBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "\n",
    "# Function to generate embeddings using mBERT with batching\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Move embeddings to CPU and store them\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.append(embeddings)\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    return np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "# Generate embeddings for the dataset with batching\n",
    "embeddings = get_embeddings(train_df['Sentence'].tolist(), batch_size=32)\n",
    "\n",
    "# Step 2: Clustering\n",
    "num_clusters = 4  # Define number of clusters (adjust based on dataset size)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Step 3: Add cluster labels to the DataFrame\n",
    "train_df['cluster'] = clusters\n",
    "\n",
    "# Step 4: Select the example closest to each cluster centroid for both labels\n",
    "few_shot_examples = []\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = train_df[train_df['cluster'] == cluster]\n",
    "    \n",
    "    # Compute distances to the centroid\n",
    "    cluster_embeddings = embeddings[cluster_data.index]\n",
    "    centroid = kmeans.cluster_centers_[cluster]\n",
    "    distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "    print(cluster_data[cluster_data['Tag'] == 'Sarcasm'])\n",
    "    \n",
    "    # Select the example closest to the centroid for each label\n",
    "    if not cluster_data[cluster_data['Tag'] == 'Sarcasm'].empty:\n",
    "        humor_idx = cluster_data[cluster_data['Tag'] == 'Sarcasm'].index[np.argmin(distances[cluster_data['Tag'] == 'Sarcasm'])]\n",
    "        print(humor_idx)\n",
    "        few_shot_examples.append(train_df.loc[humor_idx])\n",
    "        \n",
    "    if not cluster_data[cluster_data['Tag'] == 'Non-sarcasm'].empty:\n",
    "        non_humor_idx = cluster_data[cluster_data['Tag'] == 'Non-sarcasm'].index[np.argmin(distances[cluster_data['Tag'] == 'Non-sarcasm'])]\n",
    "        few_shot_examples.append(train_df.loc[non_humor_idx])\n",
    "\n",
    "# Convert the selected examples into a DataFrame\n",
    "few_shot_data = pd.DataFrame(few_shot_examples)\n",
    "\n",
    "# Display the selected few-shot examples\n",
    "print(few_shot_data[['Sentence', 'Tag', 'cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m num_sarcasm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     67\u001b[0m num_non_sarcasm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m6\u001b[39m\n\u001b[0;32m---> 69\u001b[0m selected_sarcasm \u001b[38;5;241m=\u001b[39m \u001b[43msarcasm_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_sarcasm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m selected_non_sarcasm \u001b[38;5;241m=\u001b[39m non_sarcasm_samples\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39mnum_non_sarcasm, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Combine the selected examples into a list\u001b[39;00m\n",
      "File \u001b[0;32m/data1/debajyoti/code-mix-humor-sarcasm-detection/envcodemix/lib/python3.11/site-packages/pandas/core/generic.py:6118\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m/data1/debajyoti/code-mix-humor-sarcasm-detection/envcodemix/lib/python3.11/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:945\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Step 1: Load mBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "\n",
    "# Function to generate embeddings using mBERT with batching\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Move embeddings to CPU and store them\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.append(embeddings)\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    return np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "# Generate embeddings for the dataset with batching\n",
    "embeddings = get_embeddings(train_df['Sentence'].tolist(), batch_size=32)\n",
    "\n",
    "# Step 2: Clustering\n",
    "num_clusters = 6  # Define number of clusters (adjust based on dataset size)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Step 3: Add cluster labels to the DataFrame\n",
    "train_df['cluster'] = clusters\n",
    "\n",
    "# Step 4: Select the examples for both labels\n",
    "sarcasm_samples = []\n",
    "non_sarcasm_samples = []\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = train_df[train_df['cluster'] == cluster]\n",
    "    \n",
    "    # Compute distances to the centroid\n",
    "    cluster_embeddings = embeddings[cluster_data.index]\n",
    "    centroid = kmeans.cluster_centers_[cluster]\n",
    "    distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "    \n",
    "    # Select the example closest to the centroid for each label\n",
    "    if not cluster_data[cluster_data['Tag'] == 'Sarcasm'].empty:\n",
    "        sarcasm_idx = cluster_data[cluster_data['Tag'] == 'Sarcasm'].index[np.argmin(distances[cluster_data['Tag'] == 'Sarcasm'])]\n",
    "        sarcasm_samples.append(train_df.loc[sarcasm_idx])\n",
    "        \n",
    "    if not cluster_data[cluster_data['Tag'] == 'Non-sarcasm'].empty:\n",
    "        non_sarcasm_idx = cluster_data[cluster_data['Tag'] == 'Non-sarcasm'].index[np.argmin(distances[cluster_data['Tag'] == 'Non-sarcasm'])]\n",
    "        non_sarcasm_samples.append(train_df.loc[non_sarcasm_idx])\n",
    "\n",
    "# Step 5: Select 6 non-sarcastic and 2 sarcastic examples\n",
    "sarcasm_samples = pd.DataFrame(sarcasm_samples)\n",
    "non_sarcasm_samples = pd.DataFrame(non_sarcasm_samples)\n",
    "\n",
    "# Ensure there are enough samples to select\n",
    "# num_sarcasm = min(2, len(sarcasm_samples))\n",
    "# num_non_sarcasm = min(6, len(non_sarcasm_samples))\n",
    "num_sarcasm = 2\n",
    "num_non_sarcasm = 6\n",
    "\n",
    "selected_sarcasm = sarcasm_samples.sample(n=num_sarcasm, random_state=42)\n",
    "selected_non_sarcasm = non_sarcasm_samples.sample(n=num_non_sarcasm, random_state=42)\n",
    "\n",
    "# Combine the selected examples into a list\n",
    "few_shot_examples = selected_sarcasm.to_dict(orient='records') + selected_non_sarcasm.to_dict(orient='records')\n",
    "\n",
    "# Randomly shuffle the few_shot_examples list\n",
    "random.shuffle(few_shot_examples)\n",
    "\n",
    "# Convert the selected examples into a DataFrame for display\n",
    "few_shot_data = pd.DataFrame(few_shot_examples)\n",
    "\n",
    "# Display the selected few-shot examples\n",
    "print(few_shot_data[['Sentence', 'Tag', 'cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'आप स्पष्ट रूप से एक ओबामा समर्थक हैं, वे केवल ऐसे लोग हैं जो किसी के खिलाफ मुकदमों की धमकी देने की अपनी अपमानजनक रणनीति पर परेशान नहीं होंगे जो उसके खिलाफ प्रतिकूल विज्ञापन चलाता है, इस प्रकार यह दिखाते हैं कि वह पहले संशोधन का समर्थन नहीं करता है।'}\n",
      "{'role': 'assistant', 'content': 'Non-sarcasm'}\n",
      "{'role': 'user', 'content': 'बेशक सभी के पास अपने विचारों के लिए कुछ आधार है।इससे भी इनकार नहीं किया।हालांकि ऐसे तरीके हैं जो उस \"आधार\" का उपयोग करना निश्चित रूप से एक थोपा है और समलैंगिक अधिकारों की लड़ाई एक प्रमुख उदाहरण है।कई, कई, कई लोग हैं जिन्होंने समलैंगिक विवाह और अन्य समलैंगिक अधिकारों को रोकने/ब्लॉक करने के लिए काम किया है, जब वे, खुद, समलैंगिक नहीं हैं।यह केवल निर्णय पारित नहीं है - जो कि थोप रहा है।मैं यहाँ पूछ रहा हूँ कि आर्ची, आप, जेपी, आदि खुद ही हैं।'}\n",
      "{'role': 'assistant', 'content': 'Non-sarcasm'}\n",
      "{'role': 'user', 'content': 'गलत- मुझे लगता है कि ऑलसेन उन लोगों का हवाला देते हुए बहुत विशिष्ट है, जो उन्हें लगता है कि इस उदाहरण में निशान को खत्म कर दिया है।वह एक लिंक की संभावना पर शासन नहीं कर रहा है- वह (सही रूप से IMO) कुछ श्रमिकों और प्रकाशनों को लक्षित कर रहा है।'}\n",
      "{'role': 'assistant', 'content': 'Non-sarcasm'}\n",
      "{'role': 'user', 'content': 'दरअसल, केवल वही लोग जो मैं सुनता हूं, \"सब-ह्यूमन\" के बारे में बात करते हैं, वे रचनाकार हैं।इस बात की संभावना है कि कुछ ऑस्ट्रेलियाई जीवाश्म इंडोनेशिया से एच। इरेक्टस जीवाश्मों से उतरे होंगे।और एक जीवाश्म एक \"विकासवादी\" नर्वस क्यों करेगा?विचार वास्तव में, वास्तव में गूंगा है।'}\n",
      "{'role': 'assistant', 'content': 'Non-sarcasm'}\n"
     ]
    }
   ],
   "source": [
    "# Arrange few-shot examples in the desired format\n",
    "formatted_few_shot_examples = []\n",
    "for row in few_shot_examples:\n",
    "    formatted_few_shot_examples.append({\"role\": \"user\", \"content\": row['Sentence']})\n",
    "    formatted_few_shot_examples.append({\"role\": \"assistant\", \"content\": row['Tag']})\n",
    "\n",
    "# Display the formatted few-shot examples\n",
    "for example in formatted_few_shot_examples:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the few shots in a .csv\n",
    "\n",
    "import csv\n",
    "\n",
    "# Initialize a list to hold Sentence-Tag pairs\n",
    "sentence_tag_pairs = []\n",
    "\n",
    "# Iterate through the few_shot_examples to pair user and assistant content\n",
    "for i in range(0, len(formatted_few_shot_examples), 2):\n",
    "    sentence = formatted_few_shot_examples[i][\"content\"]\n",
    "    tag = formatted_few_shot_examples[i + 1][\"content\"]\n",
    "    sentence_tag_pairs.append({\"Sentence\": sentence, \"Tag\": tag})\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/sarcasm/few_shots/iacv2_hin_llama.csv\"\n",
    "\n",
    "# Write the Sentence-Tag pairs to a CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Sentence\", \"Tag\"])\n",
    "    writer.writeheader()  # Write the header\n",
    "    writer.writerows(sentence_tag_pairs)  # Write the rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt, parse response and  generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the function to create the prompt\n",
    "def create_prompt(input, num_examples):\n",
    "\n",
    "    # System prompt \n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not.\n",
    "        If the 'Input' is sarcastic, you need to give your final 'Output' as 'Sarcasm'. \n",
    "        If the 'Input' is non-sarcastic, you need to give your final 'Output' as 'Non-sarcasm'.\"\"\"\n",
    "    }\n",
    "\n",
    "    # # System prompt \n",
    "    # system_prompt = {\n",
    "    #     \"role\": \"system\",\n",
    "    #     \"content\": \"\"\"Classify as 'Humor' or 'Non-humor'.\"\"\"\n",
    "    # }\n",
    "    \n",
    "    \n",
    "    # # Few-shot examples \n",
    "    # few_shot_examples = [\n",
    "    #     {\"role\": \"user\", \"content\": \"Why did the scarecrow win an award? Because he was outstanding in his field.\"},\n",
    "    #     {\"role\": \"assistant\", \"content\": \"Humor\"},\n",
    "    #     {\"role\": \"user\", \"content\": \"This is a straightforward business email with no jokes.\"},\n",
    "    #     {\"role\": \"assistant\", \"content\": \"Non-humor\"},\n",
    "    # ]\n",
    "\n",
    "    messages = [system_prompt] + formatted_few_shot_examples + [{\"role\": \"user\", \"content\": input}]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def parse_response(response):\n",
    "    # print(response)\n",
    "    if len(response) > 0:        \n",
    "        if \"Non-sarcasm\" in response:\n",
    "            return \"0\"\n",
    "        elif \"Sarcasm\" in response:\n",
    "            return \"1\"\n",
    "        else:# If no label is found, return None\n",
    "            return None\n",
    "\n",
    "def generate_responses(prompt, pipeline):\n",
    "\n",
    "    response = pipeline(prompt, max_new_tokens=256)[0][\"generated_text\"][-1]['content']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d88a883dc434ac789a8d5efaadcdba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/525 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 1/525 [00:00<01:50,  4.73it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  0%|          | 2/525 [00:00<01:34,  5.53it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 3/525 [00:00<01:29,  5.86it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 4/525 [00:00<01:26,  6.01it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 5/525 [00:00<01:29,  5.79it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|          | 6/525 [00:01<01:27,  5.94it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  1%|▏         | 7/525 [00:01<01:25,  6.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 8/525 [00:01<01:24,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 9/525 [00:01<01:23,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 10/525 [00:01<01:23,  6.18it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 11/525 [00:01<01:23,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 12/525 [00:02<01:26,  5.91it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  2%|▏         | 13/525 [00:02<01:25,  5.98it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|▎         | 14/525 [00:02<01:24,  6.02it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|▎         | 15/525 [00:02<01:29,  5.73it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|▎         | 16/525 [00:02<01:27,  5.83it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|▎         | 17/525 [00:02<01:26,  5.87it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  3%|▎         | 18/525 [00:03<01:24,  5.98it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|▎         | 19/525 [00:03<01:23,  6.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|▍         | 20/525 [00:03<01:22,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|▍         | 21/525 [00:03<01:21,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|▍         | 22/525 [00:03<01:21,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  4%|▍         | 23/525 [00:03<01:20,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|▍         | 24/525 [00:03<01:20,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|▍         | 25/525 [00:04<01:19,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|▍         | 26/525 [00:04<01:23,  6.01it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|▌         | 27/525 [00:04<01:22,  6.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  5%|▌         | 28/525 [00:04<01:20,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|▌         | 29/525 [00:04<01:20,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|▌         | 30/525 [00:04<01:23,  5.90it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|▌         | 31/525 [00:05<01:22,  5.98it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|▌         | 32/525 [00:05<01:21,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|▋         | 33/525 [00:05<01:20,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  6%|▋         | 34/525 [00:05<01:20,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|▋         | 35/525 [00:05<01:19,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|▋         | 36/525 [00:05<01:19,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|▋         | 37/525 [00:06<01:19,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|▋         | 38/525 [00:06<01:19,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  7%|▋         | 39/525 [00:06<01:18,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|▊         | 40/525 [00:06<01:18,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|▊         | 41/525 [00:06<01:18,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|▊         | 42/525 [00:06<01:17,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|▊         | 43/525 [00:07<01:17,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  8%|▊         | 44/525 [00:07<01:17,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|▊         | 45/525 [00:07<01:17,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|▉         | 46/525 [00:07<01:17,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|▉         | 47/525 [00:07<01:16,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|▉         | 48/525 [00:07<01:16,  6.27it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "  9%|▉         | 49/525 [00:08<01:16,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|▉         | 50/525 [00:08<01:16,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|▉         | 51/525 [00:08<01:19,  5.96it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|▉         | 52/525 [00:08<01:18,  6.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|█         | 53/525 [00:08<01:17,  6.08it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|█         | 54/525 [00:08<01:17,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 10%|█         | 55/525 [00:09<01:16,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|█         | 56/525 [00:09<01:15,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|█         | 57/525 [00:09<01:14,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|█         | 58/525 [00:09<01:14,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|█         | 59/525 [00:09<01:14,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 11%|█▏        | 60/525 [00:09<01:14,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|█▏        | 61/525 [00:10<01:14,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|█▏        | 62/525 [00:10<01:15,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|█▏        | 63/525 [00:10<01:15,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|█▏        | 64/525 [00:10<01:14,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 12%|█▏        | 65/525 [00:10<01:15,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|█▎        | 66/525 [00:10<01:18,  5.88it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|█▎        | 67/525 [00:11<01:16,  5.96it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|█▎        | 68/525 [00:11<01:15,  6.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|█▎        | 69/525 [00:11<01:14,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 13%|█▎        | 70/525 [00:11<01:13,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|█▎        | 71/525 [00:11<01:13,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|█▎        | 72/525 [00:11<01:13,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|█▍        | 73/525 [00:11<01:13,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|█▍        | 74/525 [00:12<01:12,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|█▍        | 75/525 [00:12<01:12,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 14%|█▍        | 76/525 [00:12<01:12,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|█▍        | 77/525 [00:12<01:11,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|█▍        | 78/525 [00:12<01:11,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|█▌        | 79/525 [00:12<01:11,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|█▌        | 80/525 [00:13<01:11,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 15%|█▌        | 81/525 [00:13<01:11,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|█▌        | 82/525 [00:13<01:13,  5.99it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|█▌        | 83/525 [00:13<01:13,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|█▌        | 84/525 [00:13<01:12,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|█▌        | 85/525 [00:13<01:11,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 16%|█▋        | 86/525 [00:14<01:11,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|█▋        | 87/525 [00:14<01:11,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|█▋        | 88/525 [00:14<01:10,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|█▋        | 89/525 [00:14<01:10,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|█▋        | 90/525 [00:14<01:09,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 17%|█▋        | 91/525 [00:14<01:09,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 92/525 [00:15<01:09,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 93/525 [00:15<01:08,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 94/525 [00:15<01:11,  6.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 95/525 [00:15<01:10,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 96/525 [00:15<01:09,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 18%|█▊        | 97/525 [00:15<01:09,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|█▊        | 98/525 [00:16<01:09,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|█▉        | 99/525 [00:16<01:08,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|█▉        | 100/525 [00:16<01:08,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|█▉        | 101/525 [00:16<01:07,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 19%|█▉        | 102/525 [00:16<01:07,  6.27it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|█▉        | 103/525 [00:16<01:07,  6.28it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|█▉        | 104/525 [00:16<01:07,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|██        | 105/525 [00:17<01:07,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|██        | 106/525 [00:17<01:07,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 20%|██        | 107/525 [00:17<01:06,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|██        | 108/525 [00:17<01:07,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|██        | 109/525 [00:17<01:06,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|██        | 110/525 [00:17<01:06,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|██        | 111/525 [00:18<01:06,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 21%|██▏       | 112/525 [00:18<01:06,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|██▏       | 113/525 [00:18<01:05,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|██▏       | 114/525 [00:18<01:05,  6.27it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|██▏       | 115/525 [00:18<01:08,  6.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|██▏       | 116/525 [00:18<01:07,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|██▏       | 117/525 [00:19<01:06,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 22%|██▏       | 118/525 [00:19<01:06,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|██▎       | 119/525 [00:19<01:06,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|██▎       | 120/525 [00:19<01:05,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|██▎       | 121/525 [00:19<01:05,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|██▎       | 122/525 [00:19<01:05,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 23%|██▎       | 123/525 [00:20<01:05,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|██▎       | 124/525 [00:20<01:04,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|██▍       | 125/525 [00:20<01:04,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|██▍       | 126/525 [00:20<01:04,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|██▍       | 127/525 [00:20<01:04,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 24%|██▍       | 128/525 [00:20<01:04,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|██▍       | 129/525 [00:21<01:03,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|██▍       | 130/525 [00:21<01:03,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|██▍       | 131/525 [00:21<01:06,  5.96it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|██▌       | 132/525 [00:21<01:05,  6.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 25%|██▌       | 133/525 [00:21<01:04,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▌       | 134/525 [00:21<01:03,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▌       | 135/525 [00:22<01:03,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▌       | 136/525 [00:22<01:02,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▌       | 137/525 [00:22<01:02,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▋       | 138/525 [00:22<01:02,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 26%|██▋       | 139/525 [00:22<01:02,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|██▋       | 140/525 [00:22<01:02,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|██▋       | 141/525 [00:22<01:01,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|██▋       | 142/525 [00:25<05:07,  1.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|██▋       | 143/525 [00:25<03:53,  1.64it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 27%|██▋       | 144/525 [00:25<03:01,  2.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|██▊       | 145/525 [00:25<02:24,  2.62it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|██▊       | 146/525 [00:25<01:59,  3.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|██▊       | 147/525 [00:26<01:41,  3.72it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|██▊       | 148/525 [00:26<01:29,  4.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 28%|██▊       | 149/525 [00:26<01:20,  4.67it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|██▊       | 150/525 [00:26<01:14,  5.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|██▉       | 151/525 [00:26<01:09,  5.36it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|██▉       | 152/525 [00:26<01:06,  5.60it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|██▉       | 153/525 [00:27<01:04,  5.78it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 29%|██▉       | 154/525 [00:27<01:02,  5.90it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|██▉       | 155/525 [00:27<01:01,  6.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|██▉       | 156/525 [00:27<01:00,  6.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|██▉       | 157/525 [00:27<01:00,  6.08it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|███       | 158/525 [00:27<00:59,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|███       | 159/525 [00:28<00:59,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 30%|███       | 160/525 [00:28<00:58,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|███       | 161/525 [00:28<00:58,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|███       | 162/525 [00:28<00:58,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|███       | 163/525 [00:28<00:58,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|███       | 164/525 [00:28<00:57,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 31%|███▏      | 165/525 [00:28<00:57,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|███▏      | 166/525 [00:29<00:57,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|███▏      | 167/525 [00:29<00:57,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|███▏      | 168/525 [00:29<00:57,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|███▏      | 169/525 [00:29<00:57,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 32%|███▏      | 170/525 [00:29<00:58,  6.04it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 171/525 [00:29<01:00,  5.81it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 172/525 [00:30<01:01,  5.76it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 173/525 [00:30<00:59,  5.91it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 174/525 [00:30<00:58,  6.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 33%|███▎      | 175/525 [00:30<00:57,  6.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▎      | 176/525 [00:30<00:56,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▎      | 177/525 [00:30<00:56,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▍      | 178/525 [00:31<00:58,  5.94it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▍      | 179/525 [00:31<00:57,  6.02it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▍      | 180/525 [00:31<00:56,  6.08it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 34%|███▍      | 181/525 [00:31<00:55,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|███▍      | 182/525 [00:31<00:55,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|███▍      | 183/525 [00:31<00:55,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|███▌      | 184/525 [00:32<00:55,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|███▌      | 185/525 [00:32<00:54,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 35%|███▌      | 186/525 [00:32<00:54,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|███▌      | 187/525 [00:32<00:54,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|███▌      | 188/525 [00:32<00:54,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|███▌      | 189/525 [00:32<00:53,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|███▌      | 190/525 [00:33<00:53,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 36%|███▋      | 191/525 [00:33<00:53,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|███▋      | 192/525 [00:33<00:53,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|███▋      | 193/525 [00:33<00:53,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|███▋      | 194/525 [00:33<00:52,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|███▋      | 195/525 [00:33<00:52,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 37%|███▋      | 196/525 [00:34<00:52,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 197/525 [00:34<00:52,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 198/525 [00:34<00:52,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 199/525 [00:34<00:52,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 200/525 [00:34<00:51,  6.28it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 201/525 [00:34<00:51,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 38%|███▊      | 202/525 [00:34<00:51,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|███▊      | 203/525 [00:35<00:51,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|███▉      | 204/525 [00:35<00:51,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|███▉      | 205/525 [00:35<00:51,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|███▉      | 206/525 [00:35<00:51,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 39%|███▉      | 207/525 [00:35<00:51,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|███▉      | 208/525 [00:35<00:50,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|███▉      | 209/525 [00:36<00:50,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|████      | 210/525 [00:36<00:50,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|████      | 211/525 [00:36<00:50,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 40%|████      | 212/525 [00:36<00:50,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|████      | 213/525 [00:36<00:51,  6.02it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|████      | 214/525 [00:36<00:51,  6.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|████      | 215/525 [00:37<00:50,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|████      | 216/525 [00:37<00:50,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 41%|████▏     | 217/525 [00:37<00:49,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|████▏     | 218/525 [00:37<00:49,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|████▏     | 219/525 [00:37<00:49,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|████▏     | 220/525 [00:37<00:49,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|████▏     | 221/525 [00:38<00:48,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|████▏     | 222/525 [00:38<00:48,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 42%|████▏     | 223/525 [00:38<00:48,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|████▎     | 224/525 [00:38<00:48,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|████▎     | 225/525 [00:38<00:48,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|████▎     | 226/525 [00:38<00:48,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|████▎     | 227/525 [00:39<00:47,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 43%|████▎     | 228/525 [00:39<00:47,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|████▎     | 229/525 [00:39<00:49,  5.95it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|████▍     | 230/525 [00:39<00:50,  5.81it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|████▍     | 231/525 [00:39<00:49,  5.94it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|████▍     | 232/525 [00:39<00:48,  6.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 44%|████▍     | 233/525 [00:40<00:48,  6.08it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|████▍     | 234/525 [00:40<00:47,  6.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|████▍     | 235/525 [00:40<00:47,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|████▍     | 236/525 [00:40<00:46,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|████▌     | 237/525 [00:40<00:46,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 45%|████▌     | 238/525 [00:40<00:46,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▌     | 239/525 [00:40<00:46,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▌     | 240/525 [00:41<00:45,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▌     | 241/525 [00:41<00:45,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▌     | 242/525 [00:41<00:45,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▋     | 243/525 [00:41<00:45,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 46%|████▋     | 244/525 [00:41<00:45,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|████▋     | 245/525 [00:41<00:44,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|████▋     | 246/525 [00:42<00:44,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|████▋     | 247/525 [00:42<00:44,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|████▋     | 248/525 [00:42<00:44,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 47%|████▋     | 249/525 [00:42<00:44,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|████▊     | 250/525 [00:42<00:44,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|████▊     | 251/525 [00:42<00:43,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|████▊     | 252/525 [00:43<00:43,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|████▊     | 253/525 [00:43<00:43,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 48%|████▊     | 254/525 [00:43<00:43,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|████▊     | 255/525 [00:43<00:43,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|████▉     | 256/525 [00:43<00:43,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|████▉     | 257/525 [00:43<00:42,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|████▉     | 258/525 [00:44<00:42,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 49%|████▉     | 259/525 [00:44<00:42,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|████▉     | 260/525 [00:44<00:42,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|████▉     | 261/525 [00:44<00:42,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|████▉     | 262/525 [00:44<00:42,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 263/525 [00:44<00:42,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 264/525 [00:44<00:42,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 50%|█████     | 265/525 [00:45<00:41,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|█████     | 266/525 [00:45<00:41,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|█████     | 267/525 [00:45<00:41,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|█████     | 268/525 [00:45<00:41,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|█████     | 269/525 [00:45<00:41,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 51%|█████▏    | 270/525 [00:45<00:40,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|█████▏    | 271/525 [00:46<00:40,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|█████▏    | 272/525 [00:46<00:40,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|█████▏    | 273/525 [00:46<00:40,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|█████▏    | 274/525 [00:46<00:40,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 52%|█████▏    | 275/525 [00:46<00:40,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|█████▎    | 276/525 [00:46<00:39,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|█████▎    | 277/525 [00:47<00:39,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|█████▎    | 278/525 [00:47<00:39,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|█████▎    | 279/525 [00:47<00:39,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 53%|█████▎    | 280/525 [00:47<00:39,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▎    | 281/525 [00:47<00:38,  6.27it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▎    | 282/525 [00:47<00:38,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▍    | 283/525 [00:48<00:38,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▍    | 284/525 [00:48<00:38,  6.25it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▍    | 285/525 [00:48<00:38,  6.26it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 54%|█████▍    | 286/525 [00:48<00:38,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|█████▍    | 287/525 [00:48<00:38,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|█████▍    | 288/525 [00:48<00:38,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|█████▌    | 289/525 [00:49<00:37,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|█████▌    | 290/525 [00:49<00:37,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 55%|█████▌    | 291/525 [00:49<00:37,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|█████▌    | 292/525 [00:49<00:37,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|█████▌    | 293/525 [00:49<00:37,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|█████▌    | 294/525 [00:49<00:37,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|█████▌    | 295/525 [00:49<00:38,  5.99it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 56%|█████▋    | 296/525 [00:50<00:37,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|█████▋    | 297/525 [00:50<00:37,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|█████▋    | 298/525 [00:50<00:36,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|█████▋    | 299/525 [00:50<00:36,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|█████▋    | 300/525 [00:50<00:36,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 57%|█████▋    | 301/525 [00:50<00:36,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|█████▊    | 302/525 [00:51<00:36,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|█████▊    | 303/525 [00:51<00:35,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|█████▊    | 304/525 [00:51<00:35,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|█████▊    | 305/525 [00:51<00:35,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|█████▊    | 306/525 [00:51<00:35,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 58%|█████▊    | 307/525 [00:51<00:35,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|█████▊    | 308/525 [00:52<00:35,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|█████▉    | 309/525 [00:52<00:35,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|█████▉    | 310/525 [00:52<00:34,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|█████▉    | 311/525 [00:52<00:34,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 59%|█████▉    | 312/525 [00:52<00:34,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|█████▉    | 313/525 [00:52<00:34,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|█████▉    | 314/525 [00:54<02:32,  1.38it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|██████    | 315/525 [00:55<01:56,  1.80it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|██████    | 316/525 [00:55<01:31,  2.29it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 60%|██████    | 317/525 [00:55<01:13,  2.82it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|██████    | 318/525 [00:55<01:01,  3.37it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|██████    | 319/525 [00:55<00:54,  3.81it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|██████    | 320/525 [00:55<00:47,  4.31it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|██████    | 321/525 [00:56<00:43,  4.73it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 61%|██████▏   | 322/525 [00:56<00:39,  5.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 323/525 [00:56<00:37,  5.40it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 324/525 [00:56<00:35,  5.61it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 325/525 [00:56<00:34,  5.78it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 326/525 [00:56<00:33,  5.90it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 327/525 [00:57<00:33,  5.99it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 62%|██████▏   | 328/525 [00:57<00:32,  6.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|██████▎   | 329/525 [00:57<00:32,  6.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|██████▎   | 330/525 [00:57<00:31,  6.12it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|██████▎   | 331/525 [00:57<00:32,  5.89it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|██████▎   | 332/525 [00:57<00:32,  5.99it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 63%|██████▎   | 333/525 [00:58<00:31,  6.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|██████▎   | 334/525 [00:58<00:31,  6.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|██████▍   | 335/525 [00:58<00:31,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|██████▍   | 336/525 [00:58<00:30,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|██████▍   | 337/525 [00:58<00:30,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 64%|██████▍   | 338/525 [00:58<00:30,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|██████▍   | 339/525 [00:59<00:30,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|██████▍   | 340/525 [00:59<00:29,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|██████▍   | 341/525 [00:59<00:29,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|██████▌   | 342/525 [00:59<00:29,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 65%|██████▌   | 343/525 [00:59<00:29,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▌   | 344/525 [00:59<00:29,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▌   | 345/525 [00:59<00:28,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▌   | 346/525 [01:00<00:28,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▌   | 347/525 [01:00<00:28,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▋   | 348/525 [01:00<00:28,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 66%|██████▋   | 349/525 [01:00<00:28,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 350/525 [01:00<00:28,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 351/525 [01:00<00:28,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 352/525 [01:01<00:27,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 353/525 [01:01<00:27,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 67%|██████▋   | 354/525 [01:01<00:27,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|██████▊   | 355/525 [01:01<00:27,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|██████▊   | 356/525 [01:01<00:27,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|██████▊   | 357/525 [01:01<00:27,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|██████▊   | 358/525 [01:02<00:26,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 68%|██████▊   | 359/525 [01:02<00:26,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|██████▊   | 360/525 [01:02<00:26,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|██████▉   | 361/525 [01:02<00:27,  5.95it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|██████▉   | 362/525 [01:02<00:27,  6.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|██████▉   | 363/525 [01:02<00:26,  6.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 69%|██████▉   | 364/525 [01:03<00:26,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|██████▉   | 365/525 [01:03<00:26,  5.94it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|██████▉   | 366/525 [01:03<00:26,  6.01it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|██████▉   | 367/525 [01:03<00:26,  6.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|███████   | 368/525 [01:03<00:25,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|███████   | 369/525 [01:03<00:25,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 70%|███████   | 370/525 [01:04<00:25,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|███████   | 371/525 [01:04<00:25,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|███████   | 372/525 [01:04<00:24,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|███████   | 373/525 [01:04<00:24,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|███████   | 374/525 [01:04<00:24,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 71%|███████▏  | 375/525 [01:04<00:24,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|███████▏  | 376/525 [01:05<00:24,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|███████▏  | 377/525 [01:05<00:23,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|███████▏  | 378/525 [01:05<00:23,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|███████▏  | 379/525 [01:05<00:23,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 72%|███████▏  | 380/525 [01:05<00:23,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|███████▎  | 381/525 [01:05<00:23,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|███████▎  | 382/525 [01:05<00:23,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|███████▎  | 383/525 [01:06<00:22,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|███████▎  | 384/525 [01:06<00:22,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 73%|███████▎  | 385/525 [01:06<00:22,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▎  | 386/525 [01:06<00:22,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▎  | 387/525 [01:06<00:22,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▍  | 388/525 [01:06<00:22,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▍  | 389/525 [01:07<00:22,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▍  | 390/525 [01:07<00:21,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 74%|███████▍  | 391/525 [01:07<00:21,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|███████▍  | 392/525 [01:07<00:21,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|███████▍  | 393/525 [01:07<00:21,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|███████▌  | 394/525 [01:07<00:21,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|███████▌  | 395/525 [01:08<00:21,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 75%|███████▌  | 396/525 [01:08<00:20,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|███████▌  | 397/525 [01:08<00:20,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|███████▌  | 398/525 [01:08<00:20,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|███████▌  | 399/525 [01:08<00:20,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|███████▌  | 400/525 [01:08<00:20,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 76%|███████▋  | 401/525 [01:09<00:20,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|███████▋  | 402/525 [01:09<00:19,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|███████▋  | 403/525 [01:09<00:19,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|███████▋  | 404/525 [01:09<00:19,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|███████▋  | 405/525 [01:09<00:19,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 77%|███████▋  | 406/525 [01:09<00:19,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|███████▊  | 407/525 [01:10<00:18,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|███████▊  | 408/525 [01:10<00:18,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|███████▊  | 409/525 [01:10<00:18,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|███████▊  | 410/525 [01:10<00:18,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|███████▊  | 411/525 [01:10<00:18,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 78%|███████▊  | 412/525 [01:10<00:18,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|███████▊  | 413/525 [01:10<00:18,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|███████▉  | 414/525 [01:11<00:17,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|███████▉  | 415/525 [01:11<00:17,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|███████▉  | 416/525 [01:11<00:18,  5.91it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 79%|███████▉  | 417/525 [01:11<00:17,  6.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|███████▉  | 418/525 [01:11<00:17,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|███████▉  | 419/525 [01:11<00:17,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|████████  | 420/525 [01:12<00:17,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|████████  | 421/525 [01:12<00:16,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 80%|████████  | 422/525 [01:12<00:16,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|████████  | 423/525 [01:12<00:16,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|████████  | 424/525 [01:12<00:16,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|████████  | 425/525 [01:12<00:16,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|████████  | 426/525 [01:13<00:15,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 81%|████████▏ | 427/525 [01:13<00:15,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 428/525 [01:13<00:15,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 429/525 [01:13<00:15,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 430/525 [01:13<00:15,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 431/525 [01:13<00:15,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 432/525 [01:14<00:14,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 82%|████████▏ | 433/525 [01:14<00:14,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|████████▎ | 434/525 [01:14<00:14,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|████████▎ | 435/525 [01:14<00:14,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|████████▎ | 436/525 [01:14<00:14,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|████████▎ | 437/525 [01:14<00:14,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 83%|████████▎ | 438/525 [01:15<00:14,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|████████▎ | 439/525 [01:15<00:13,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|████████▍ | 440/525 [01:15<00:13,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|████████▍ | 441/525 [01:15<00:13,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|████████▍ | 442/525 [01:15<00:13,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 84%|████████▍ | 443/525 [01:15<00:13,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|████████▍ | 444/525 [01:16<00:13,  5.95it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|████████▍ | 445/525 [01:16<00:13,  6.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|████████▍ | 446/525 [01:16<00:13,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|████████▌ | 447/525 [01:16<00:12,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 85%|████████▌ | 448/525 [01:16<00:13,  5.86it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|████████▌ | 449/525 [01:16<00:12,  5.94it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|████████▌ | 450/525 [01:17<00:12,  6.00it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|████████▌ | 451/525 [01:17<00:12,  6.05it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|████████▌ | 452/525 [01:17<00:11,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|████████▋ | 453/525 [01:17<00:11,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 86%|████████▋ | 454/525 [01:17<00:11,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|████████▋ | 455/525 [01:17<00:11,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|████████▋ | 456/525 [01:18<00:11,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|████████▋ | 457/525 [01:18<00:11,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|████████▋ | 458/525 [01:18<00:10,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 87%|████████▋ | 459/525 [01:18<00:10,  6.17it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|████████▊ | 460/525 [01:18<00:10,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|████████▊ | 461/525 [01:18<00:10,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|████████▊ | 462/525 [01:18<00:10,  6.16it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|████████▊ | 463/525 [01:19<00:10,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 88%|████████▊ | 464/525 [01:19<00:09,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|████████▊ | 465/525 [01:19<00:09,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|████████▉ | 466/525 [01:19<00:09,  5.98it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|████████▉ | 467/525 [01:19<00:09,  6.07it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|████████▉ | 468/525 [01:19<00:09,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 89%|████████▉ | 469/525 [01:20<00:09,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|████████▉ | 470/525 [01:20<00:09,  5.94it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|████████▉ | 471/525 [01:20<00:08,  6.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|████████▉ | 472/525 [01:20<00:08,  6.10it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|█████████ | 473/525 [01:20<00:08,  6.13it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|█████████ | 474/525 [01:20<00:08,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 90%|█████████ | 475/525 [01:21<00:08,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|█████████ | 476/525 [01:21<00:07,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|█████████ | 477/525 [01:21<00:07,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|█████████ | 478/525 [01:21<00:07,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|█████████ | 479/525 [01:21<00:07,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 91%|█████████▏| 480/525 [01:21<00:07,  5.97it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|█████████▏| 481/525 [01:22<00:07,  6.03it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|█████████▏| 482/525 [01:22<00:07,  6.09it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|█████████▏| 483/525 [01:22<00:06,  6.14it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|█████████▏| 484/525 [01:22<00:06,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 92%|█████████▏| 485/525 [01:22<00:06,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|█████████▎| 486/525 [01:22<00:06,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|█████████▎| 487/525 [01:23<00:06,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|█████████▎| 488/525 [01:23<00:05,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|█████████▎| 489/525 [01:23<00:05,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 93%|█████████▎| 490/525 [01:23<00:05,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|█████████▎| 491/525 [01:23<00:05,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|█████████▎| 492/525 [01:23<00:05,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|█████████▍| 493/525 [01:24<00:05,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|█████████▍| 494/525 [01:24<00:04,  6.23it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|█████████▍| 495/525 [01:24<00:04,  6.24it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 94%|█████████▍| 496/525 [01:24<00:05,  5.53it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|█████████▍| 497/525 [01:24<00:04,  5.68it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|█████████▍| 498/525 [01:24<00:04,  5.83it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|█████████▌| 499/525 [01:25<00:04,  5.93it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|█████████▌| 500/525 [01:25<00:04,  6.01it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 95%|█████████▌| 501/525 [01:25<00:04,  5.85it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|█████████▌| 502/525 [01:25<00:03,  5.97it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|█████████▌| 503/525 [01:25<00:03,  6.06it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|█████████▌| 504/525 [01:25<00:03,  6.11it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|█████████▌| 505/525 [01:26<00:03,  6.15it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 96%|█████████▋| 506/525 [01:26<00:03,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|█████████▋| 507/525 [01:26<00:02,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|█████████▋| 508/525 [01:26<00:02,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|█████████▋| 509/525 [01:26<00:02,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|█████████▋| 510/525 [01:26<00:02,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 97%|█████████▋| 511/525 [01:27<00:02,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 512/525 [01:27<00:02,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 513/525 [01:27<00:01,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 514/525 [01:27<00:01,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 515/525 [01:27<00:01,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 516/525 [01:27<00:01,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 98%|█████████▊| 517/525 [01:27<00:01,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|█████████▊| 518/525 [01:28<00:01,  6.18it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|█████████▉| 519/525 [01:28<00:00,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|█████████▉| 520/525 [01:28<00:00,  6.19it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|█████████▉| 521/525 [01:28<00:00,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      " 99%|█████████▉| 522/525 [01:28<00:00,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|█████████▉| 523/525 [01:28<00:00,  6.22it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|█████████▉| 524/525 [01:29<00:00,  6.21it/s]Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "100%|██████████| 525/525 [01:29<00:00,  5.88it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_data(data_filepath, output_filepath):\n",
    "    # df = pd.read_csv(data_filepath)\n",
    "    df = test_df\n",
    "    # df = df[:5]\n",
    "    \n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    num_examples = 15 # number of shots in few-shot\n",
    "    # Loop over the DataFrame and pass the text to generate response\n",
    "    for index, row in tqdm(list(df.iterrows())):\n",
    "        prompt = create_prompt(row['Sentence'], num_examples)\n",
    "        model_response = generate_responses(prompt, pipeline)\n",
    "        # print(model_response)\n",
    "        generated_label = parse_response(model_response)\n",
    "\n",
    "        # veracity, explanation = parse_response(model_response)\n",
    "        \n",
    "        results.append({\n",
    "            'Sentence': row['Sentence'],\n",
    "            'Label': row['Tag'],\n",
    "            'Response': model_response,\n",
    "            'Gen_label': generated_label,\n",
    "            # 'Explanation': explanation\n",
    "        })\n",
    "        # break\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example file paths, replace with your actual paths\n",
    "data_filepath = '/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/test.csv'\n",
    "output_filepath = '/data1/debajyoti/test/llms/data/humor'\n",
    "\n",
    "# Run the data processing\n",
    "result = process_data(data_filepath, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gen_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mera bhanja mujhe \"papa ka sala\" bulata hai......</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aur aap a0ni politics karne me vyast hai.. #Bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theek hai waha at least Janki ma ka mandir hai...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir mujhe cricket acdemy join karna hai mai ka...</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>aaj bjp aur chadhi gang aise khus ho rahe hai ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>@SGanguly99 sir aapnio jodi aamar saath na den...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>#Irony: Pran ka pran chala gaya.. RIP Sher Khan!</td>\n",
       "      <td>1</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Ye bhi mat bhulo ki triple talaq ko ban lagane...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>#ViruPanti @virendersehwag @cricketaakash DHON...</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Label     Response  \\\n",
       "0    Mera bhanja mujhe \"papa ka sala\" bulata hai......      0      Sarcasm   \n",
       "1    Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...      0      Sarcasm   \n",
       "2    aur aap a0ni politics karne me vyast hai.. #Bi...      0      Sarcasm   \n",
       "3    Theek hai waha at least Janki ma ka mandir hai...      0      Sarcasm   \n",
       "4    Sir mujhe cricket acdemy join karna hai mai ka...      0  Non-sarcasm   \n",
       "..                                                 ...    ...          ...   \n",
       "520  aaj bjp aur chadhi gang aise khus ho rahe hai ...      0      Sarcasm   \n",
       "521  @SGanguly99 sir aapnio jodi aamar saath na den...      0      Sarcasm   \n",
       "522   #Irony: Pran ka pran chala gaya.. RIP Sher Khan!      1      Sarcasm   \n",
       "523  Ye bhi mat bhulo ki triple talaq ko ban lagane...      0      Sarcasm   \n",
       "524  #ViruPanti @virendersehwag @cricketaakash DHON...      0      Sarcasm   \n",
       "\n",
       "    Gen_label  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "..        ...  \n",
       "520         1  \n",
       "521         1  \n",
       "522         1  \n",
       "523         1  \n",
       "524         1  \n",
       "\n",
       "[525 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envcodemix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
