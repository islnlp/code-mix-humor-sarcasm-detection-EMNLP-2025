{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# humor_df = pd.read_csv(\"/data1/debajyoti/test/llms/data/1Humour_Codemix.csv\") # code-mixed humor dataset\n",
    "# sarcasm_df = pd.read_csv(\"/data1/debajyoti/test/llms/data/1Sarcasm_Codemix.csv\") # code-mixed sarcasm dataset\n",
    "\n",
    "# def stratified_split(df):   # dataframe (df) is required as argument\n",
    "#     X, y = list(df['Sentence']), list(df['Tag'])    # X: data, y: labels\n",
    "    \n",
    "#     # 80(train), 10(val), 10(test) split of the data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=0.20, stratify=y, random_state=42)\n",
    "#     X_val, X_test, y_val, y_test = train_test_split(\n",
    "#         X_test, y_test, test_size=0.50, stratify=y_test, random_state=42)\n",
    "#     cols = {\"Sentence\" : X_train, \"Tag\" : y_train}\n",
    "#     train_df = pd.DataFrame(cols)   # train dataframe\n",
    "#     cols = {\"Sentence\" : X_val, \"Tag\" : y_val}\n",
    "#     val_df = pd.DataFrame(cols)     # validation dataframe\n",
    "#     cols = {\"Sentence\" : X_test, \"Tag\" : y_test}\n",
    "#     test_df = pd.DataFrame(cols)    # test dataframe\n",
    "    \n",
    "#     return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, val_df, test_df = stratified_split(sarcasm_df)  # function call\n",
    "\n",
    "# # save the stratified-splits in csv\n",
    "# train_df.to_csv('/data1/debajyoti/test/llms/data/sarcasm/train.csv', index=False)\n",
    "# val_df.to_csv('/data1/debajyoti/test/llms/data/sarcasm/val.csv', index=False)\n",
    "# test_df.to_csv('/data1/debajyoti/test/llms/data/sarcasm/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 2 takiye ki naukri main mera lakhon ka worl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Naam : Viv Richards\\nBaap ka naam : Master Di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sakshi Maharaj is BJP's Digvijaya Singh.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj @British_Airways ki toh lag gayi bhai.\\nHa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghanta development hoga! Saare paise to electi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hum to Aam Aadmi hain ji, woh Megalomaniac hai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Neend nahi aati hai raaton mein?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Ghar mein Bipasha Basu ki photo rakhne se bhoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tu na ja mere baadshah ek waade ke liye, maa c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Tag\n",
       "0    Is 2 takiye ki naukri main mera lakhon ka worl...    0\n",
       "1    \"Naam : Viv Richards\\nBaap ka naam : Master Di...    1\n",
       "2             Sakshi Maharaj is BJP's Digvijaya Singh.    1\n",
       "3    Aaj @British_Airways ki toh lag gayi bhai.\\nHa...    1\n",
       "4    Ghanta development hoga! Saare paise to electi...    1\n",
       "..                                                 ...  ...\n",
       "291  Hum to Aam Aadmi hain ji, woh Megalomaniac hai...    1\n",
       "292                   Neend nahi aati hai raaton mein?    0\n",
       "293  Ghar mein Bipasha Basu ki photo rakhne se bhoo...    1\n",
       "294    Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V    0\n",
       "295  Tu na ja mere baadshah ek waade ke liye, maa c...    1\n",
       "\n",
       "[296 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_eng = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Humour_English(NEW).csv\")\n",
    "# train_df_eng = train_df_eng[:2000]\n",
    "# train_df_hin = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Humour_English(NEW).csv\")\n",
    "# train_df_hin = train_df_hin[:2000]\n",
    "# train_df = pd.concat([train_df_eng, train_df_hin], ignore_index=True)\n",
    "# train_df = train_df_hin\n",
    "train_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/train.csv\")\n",
    "val_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/val.csv\")\n",
    "test_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/test.csv\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jyotiraditya Scindia is like \"Rassi jal gayee ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ishant Sharma ko bahut late utaara.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.@twinitisha neeche plug nikla hua hai..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj agar India final me hota to kam se kam New...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 stages of life of Mechanical Engineer:\\n\\n1)...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>Nitish &amp; Lalu scared of Modi so much that agar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>.@ShirishKunder Sabzi bana ke rakhna nahi to F...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>\"BARKHA se bacha lu tujhe seene se laga lu, aa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>\"Bol raha hai mere saath debate karega.. Muh k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Pakistan ko har world cup ke baad captain bada...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Tag\n",
       "0     Jyotiraditya Scindia is like \"Rassi jal gayee ...    1\n",
       "1                   Ishant Sharma ko bahut late utaara.    1\n",
       "2              .@twinitisha neeche plug nikla hua hai..    0\n",
       "3     Aaj agar India final me hota to kam se kam New...    0\n",
       "4     3 stages of life of Mechanical Engineer:\\n\\n1)...    1\n",
       "...                                                 ...  ...\n",
       "2355  Nitish & Lalu scared of Modi so much that agar...    1\n",
       "2356  .@ShirishKunder Sabzi bana ke rakhna nahi to F...    1\n",
       "2357  \"BARKHA se bacha lu tujhe seene se laga lu, aa...    0\n",
       "2358  \"Bol raha hai mere saath debate karega.. Muh k...    0\n",
       "2359  Pakistan ko har world cup ke baad captain bada...    0\n",
       "\n",
       "[2360 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@BJP4India se koi umeed na rakhe.. In chutiyo...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mere ghar ka khaana sabse best hai. Food blogg...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ab dekhna ye hai @aloknath ji Tara ka kanyadaa...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bhai kuch kal ke liye bhi chhod de..\\n\\nRT @Ec...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chetan 'English ka Mast Ram' Bhagat \\n\\n#Celeb...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>.@OfficeOfRG bhai Dilli se to 1AC me gaye ho.....</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>.@SRKswarrior1 bas bata raha hu intolerance ky...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>Kal gaadi ke niche a gaya. Kismat achi thi ki ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>Chitrahar mein bijlee udd gayi</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "      <td>Misbah: Bhai kal match jeet gaye to english me...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2360 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence        Tag\n",
       "0     .@BJP4India se koi umeed na rakhe.. In chutiyo...      Humor\n",
       "1     Mere ghar ka khaana sabse best hai. Food blogg...      Humor\n",
       "2     Ab dekhna ye hai @aloknath ji Tara ka kanyadaa...  Non-humor\n",
       "3     Bhai kuch kal ke liye bhi chhod de..\\n\\nRT @Ec...  Non-humor\n",
       "4     Chetan 'English ka Mast Ram' Bhagat \\n\\n#Celeb...      Humor\n",
       "...                                                 ...        ...\n",
       "2355  .@OfficeOfRG bhai Dilli se to 1AC me gaye ho.....  Non-humor\n",
       "2356  .@SRKswarrior1 bas bata raha hu intolerance ky...  Non-humor\n",
       "2357  Kal gaadi ke niche a gaya. Kismat achi thi ki ...      Humor\n",
       "2358                     Chitrahar mein bijlee udd gayi      Humor\n",
       "2359  Misbah: Bhai kal match jeet gaye to english me...      Humor\n",
       "\n",
       "[2360 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Tag'] = train_df['Tag'].map({0: 'Non-humor', 1: 'Humor'})\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b3200bd9c0481296c1b92685e4f499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'assistant', 'content': 'Humor.'}\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"\"\"You are a humor recognition assistant judging if an 'Input' is humorous or not. No need to consider any prior context.\n",
    "    If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \n",
    "    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi chaltapic.twitter.com/bOLAEk0g4E\"},\n",
    "]\n",
    "\n",
    "outputs = pipeline(\n",
    "    messages,\n",
    "    max_new_tokens=256,\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing few-shots for prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2126\n",
      "1021\n",
      "462\n",
      "1302\n",
      "                                               Sentence        Tag  cluster\n",
      "2126  TL pe koi adarsh liberal jisko patakho se dikk...      Humor        0\n",
      "2212  Chyamaila Hou de kharcha #Gudipadwapic.twitter...  Non-humor        0\n",
      "1021  AAP walon ke ye haal hai ki agar Modi pe joke ...      Humor        1\n",
      "718   1k rt tweets ko bhi aaj kal 5-7 rts milte hai....  Non-humor        1\n",
      "462   Ab jake mera tweet padha bhai ne. Sala itni de...      Humor        2\n",
      "298   Baa ji @BDUTT main to bolta hoon Indrani ki ja...  Non-humor        2\n",
      "1302  Bhai @imVkohli ye century pe century lagakar a...      Humor        3\n",
      "1704  Kabse iss pyaase jhagadte TL par, sense ki ek ...  Non-humor        3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load mBERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased').to(device)\n",
    "\n",
    "# Function to generate embeddings using mBERT with batching\n",
    "def get_embeddings(texts, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        # Move embeddings to CPU and store them\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "        all_embeddings.append(embeddings)\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    return np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "# Generate embeddings for the dataset with batching\n",
    "embeddings = get_embeddings(train_df['Sentence'].tolist(), batch_size=32)\n",
    "\n",
    "# Step 2: Clustering\n",
    "num_clusters = 4  # Define number of clusters (adjust based on dataset size)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Step 3: Add cluster labels to the DataFrame\n",
    "train_df['cluster'] = clusters\n",
    "\n",
    "# Step 4: Select the example closest to each cluster centroid for both labels\n",
    "few_shot_examples = []\n",
    "\n",
    "for cluster in range(num_clusters):\n",
    "    cluster_data = train_df[train_df['cluster'] == cluster]\n",
    "    \n",
    "    # Compute distances to the centroid\n",
    "    cluster_embeddings = embeddings[cluster_data.index]\n",
    "    centroid = kmeans.cluster_centers_[cluster]\n",
    "    distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)\n",
    "    \n",
    "    # Select the example closest to the centroid for each label\n",
    "    if not cluster_data[cluster_data['Tag'] == 'Humor'].empty:\n",
    "        humor_idx = cluster_data[cluster_data['Tag'] == 'Humor'].index[np.argmin(distances[cluster_data['Tag'] == 'Humor'])]\n",
    "        print(humor_idx)\n",
    "        few_shot_examples.append(train_df.loc[humor_idx])\n",
    "        \n",
    "    if not cluster_data[cluster_data['Tag'] == 'Non-humor'].empty:\n",
    "        non_humor_idx = cluster_data[cluster_data['Tag'] == 'Non-humor'].index[np.argmin(distances[cluster_data['Tag'] == 'Non-humor'])]\n",
    "        few_shot_examples.append(train_df.loc[non_humor_idx])\n",
    "\n",
    "# Convert the selected examples into a DataFrame\n",
    "few_shot_data = pd.DataFrame(few_shot_examples)\n",
    "\n",
    "# Display the selected few-shot examples\n",
    "print(few_shot_data[['Sentence', 'Tag', 'cluster']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user', 'content': 'TL pe koi adarsh liberal jisko patakho se dikkat ho.. Ye bomb apni gaand me bhar le.. Batti mein laga doongapic.twitter.com/nva3UI1BHD'}\n",
      "{'role': 'assistant', 'content': 'Humor'}\n",
      "{'role': 'user', 'content': 'Chyamaila Hou de kharcha #Gudipadwapic.twitter.com/nNKEg1O7Ek'}\n",
      "{'role': 'assistant', 'content': 'Non-humor'}\n",
      "{'role': 'user', 'content': 'AAP walon ke ye haal hai ki agar Modi pe joke maro to bhi unhe tarif hi lagti hai.'}\n",
      "{'role': 'assistant', 'content': 'Humor'}\n",
      "{'role': 'user', 'content': '1k rt tweets ko bhi aaj kal 5-7 rts milte hai. Kya zamana aa gaya hai.'}\n",
      "{'role': 'assistant', 'content': 'Non-humor'}\n",
      "{'role': 'user', 'content': 'Ab jake mera tweet padha bhai ne. Sala itni der se anushka sharma ki TL pe jasoosi kar raha tha !!'}\n",
      "{'role': 'assistant', 'content': 'Humor'}\n",
      "{'role': 'user', 'content': 'Baa ji @BDUTT main to bolta hoon Indrani ki jagah Siddhrtha par muder ka case chalaya jaye. Kya bolti ho?'}\n",
      "{'role': 'assistant', 'content': 'Non-humor'}\n",
      "{'role': 'user', 'content': 'Bhai @imVkohli ye century pe century lagakar aadat kharab kar rahe ho hamari. Fir tumhe hi problem hogi.'}\n",
      "{'role': 'assistant', 'content': 'Humor'}\n",
      "{'role': 'user', 'content': 'Kabse iss pyaase jhagadte TL par, sense ki ek boondh tak nahi giri.'}\n",
      "{'role': 'assistant', 'content': 'Non-humor'}\n"
     ]
    }
   ],
   "source": [
    "# Arrange few-shot examples in the desired format\n",
    "formatted_few_shot_examples = []\n",
    "for row in few_shot_examples:\n",
    "    formatted_few_shot_examples.append({\"role\": \"user\", \"content\": row['Sentence']})\n",
    "    formatted_few_shot_examples.append({\"role\": \"assistant\", \"content\": row['Tag']})\n",
    "\n",
    "# Display the formatted few-shot examples\n",
    "for example in formatted_few_shot_examples:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Store the few shots in a .csv\n",
    "\n",
    "import csv\n",
    "\n",
    "# Initialize a list to hold Sentence-Tag pairs\n",
    "sentence_tag_pairs = []\n",
    "\n",
    "# Iterate through the few_shot_examples to pair user and assistant content\n",
    "for i in range(0, len(formatted_few_shot_examples), 2):\n",
    "    sentence = formatted_few_shot_examples[i][\"content\"]\n",
    "    tag = formatted_few_shot_examples[i + 1][\"content\"]\n",
    "    sentence_tag_pairs.append({\"Sentence\": sentence, \"Tag\": tag})\n",
    "\n",
    "# Define the CSV file path\n",
    "csv_file_path = \"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/humor/few_shots/cm.csv\"\n",
    "\n",
    "# Write the Sentence-Tag pairs to a CSV file\n",
    "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"Sentence\", \"Tag\"])\n",
    "    writer.writeheader()  # Write the header\n",
    "    writer.writerows(sentence_tag_pairs)  # Write the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TL pe koi adarsh liberal jisko patakho se dikk...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chyamaila Hou de kharcha #Gudipadwapic.twitter...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAP walon ke ye haal hai ki agar Modi pe joke ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1k rt tweets ko bhi aaj kal 5-7 rts milte hai....</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ab jake mera tweet padha bhai ne. Sala itni de...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baa ji @BDUTT main to bolta hoon Indrani ki ja...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bhai @imVkohli ye century pe century lagakar a...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kabse iss pyaase jhagadte TL par, sense ki ek ...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Tag\n",
       "0  TL pe koi adarsh liberal jisko patakho se dikk...      Humor\n",
       "1  Chyamaila Hou de kharcha #Gudipadwapic.twitter...  Non-humor\n",
       "2  AAP walon ke ye haal hai ki agar Modi pe joke ...      Humor\n",
       "3  1k rt tweets ko bhi aaj kal 5-7 rts milte hai....  Non-humor\n",
       "4  Ab jake mera tweet padha bhai ne. Sala itni de...      Humor\n",
       "5  Baa ji @BDUTT main to bolta hoon Indrani ki ja...  Non-humor\n",
       "6  Bhai @imVkohli ye century pe century lagakar a...      Humor\n",
       "7  Kabse iss pyaase jhagadte TL par, sense ki ek ...  Non-humor"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/humor/few_shots/cm.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'TL pe koi adarsh liberal jisko patakho se dikkat ho.. Ye bomb apni gaand me bhar le.. Batti mein laga doongapic.twitter.com/nva3UI1BHD'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'Chyamaila Hou de kharcha #Gudipadwapic.twitter.com/nNKEg1O7Ek'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'AAP walon ke ye haal hai ki agar Modi pe joke maro to bhi unhe tarif hi lagti hai.'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': '1k rt tweets ko bhi aaj kal 5-7 rts milte hai. Kya zamana aa gaya hai.'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'Ab jake mera tweet padha bhai ne. Sala itni der se anushka sharma ki TL pe jasoosi kar raha tha !!'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'Baa ji @BDUTT main to bolta hoon Indrani ki jagah Siddhrtha par muder ka case chalaya jaye. Kya bolti ho?'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'Bhai @imVkohli ye century pe century lagakar aadat kharab kar rahe ho hamari. Fir tumhe hi problem hogi.'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': 'Kabse iss pyaase jhagadte TL par, sense ki ek boondh tak nahi giri.'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to specified format\n",
    "formatted_few_shot_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted_few_shot_examples.append({'role': 'user', 'content': row['Sentence']})\n",
    "    formatted_few_shot_examples.append({'role': 'assistant', 'content': row['Tag']})\n",
    "    \n",
    "formatted_few_shot_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt, parse response and  generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the function to create the prompt\n",
    "def create_prompt(input, num_examples):\n",
    "\n",
    "    # System prompt \n",
    "    system_prompt = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a humor recognition assistant judging if an 'Input' is sarcastic or not.\n",
    "        If the 'Input' is sarcastic, you need to give your final 'Output' as 'Humor'. \n",
    "        If the 'Input' is non-sarcastic, you need to give your final 'Output' as 'Non-humor'.\"\"\"\n",
    "    }\n",
    "\n",
    "    # # System prompt \n",
    "    # system_prompt = {\n",
    "    #     \"role\": \"system\",\n",
    "    #     \"content\": \"\"\"Classify as 'Humor' or 'Non-humor'.\"\"\"\n",
    "    # }\n",
    "    \n",
    "    \n",
    "    # # Few-shot examples \n",
    "    # few_shot_examples = [\n",
    "    #     {\"role\": \"user\", \"content\": \"Why did the scarecrow win an award? Because he was outstanding in his field.\"},\n",
    "    #     {\"role\": \"assistant\", \"content\": \"Humor\"},\n",
    "    #     {\"role\": \"user\", \"content\": \"This is a straightforward business email with no jokes.\"},\n",
    "    #     {\"role\": \"assistant\", \"content\": \"Non-humor\"},\n",
    "    # ]\n",
    "\n",
    "    messages = [system_prompt] + formatted_few_shot_examples + [{\"role\": \"user\", \"content\": input}]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def parse_response(response):\n",
    "    \"\"\"\n",
    "    Extracts the classification label and explanation from the model-generated response,\n",
    "    starting from the line containing the final \"Answer:\".\n",
    "\n",
    "    Args:\n",
    "        response (str): The response generated by the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the classification label (\"Humor\" or \"Non-humor\") \n",
    "               and the explanation text.\n",
    "    \"\"\"\n",
    "    # print(response)\n",
    "    if len(response) > 0:        \n",
    "        if \"Non-humor\" in response:\n",
    "            return \"0\"\n",
    "        elif \"Humor\" in response:\n",
    "            return \"1\"\n",
    "        else:# If no label is found, return None\n",
    "            return None\n",
    "\n",
    "def generate_responses(prompt, pipeline):\n",
    "\n",
    "    response = pipeline(prompt, max_new_tokens=256)[0][\"generated_text\"][-1]['content']\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebbea1059ad4aa5b0efaed7f6a07900",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/296 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  0%|          | 1/296 [00:00<00:32,  8.98it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  1%|          | 2/296 [00:00<00:31,  9.25it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  1%|          | 3/296 [00:00<00:31,  9.26it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  1%|▏         | 4/296 [00:00<00:31,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  2%|▏         | 5/296 [00:00<00:30,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  2%|▏         | 6/296 [00:00<00:30,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  2%|▏         | 7/296 [00:00<00:30,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  3%|▎         | 8/296 [00:00<00:30,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  3%|▎         | 9/296 [00:00<00:29,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  3%|▎         | 10/296 [00:01<00:29,  9.54it/s]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  4%|▎         | 11/296 [00:01<00:30,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  4%|▍         | 12/296 [00:01<00:30,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  4%|▍         | 13/296 [00:01<00:29,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  5%|▍         | 14/296 [00:01<00:29,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  5%|▌         | 15/296 [00:01<00:29,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  5%|▌         | 16/296 [00:01<00:29,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  6%|▌         | 17/296 [00:01<00:29,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  6%|▌         | 18/296 [00:01<00:30,  9.04it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  6%|▋         | 19/296 [00:02<00:30,  9.20it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  7%|▋         | 20/296 [00:02<00:29,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  7%|▋         | 21/296 [00:02<00:31,  8.79it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  7%|▋         | 22/296 [00:02<00:30,  8.98it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  8%|▊         | 23/296 [00:02<00:31,  8.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  8%|▊         | 24/296 [00:02<00:30,  8.87it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  8%|▊         | 25/296 [00:02<00:29,  9.06it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  9%|▉         | 26/296 [00:02<00:29,  9.24it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  9%|▉         | 27/296 [00:02<00:28,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "  9%|▉         | 28/296 [00:03<00:28,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 10%|▉         | 29/296 [00:03<00:28,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 10%|█         | 30/296 [00:03<00:27,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 10%|█         | 31/296 [00:03<00:27,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 11%|█         | 32/296 [00:03<00:27,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 11%|█         | 33/296 [00:03<00:27,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 11%|█▏        | 34/296 [00:03<00:27,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 12%|█▏        | 35/296 [00:03<00:27,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 12%|█▏        | 36/296 [00:03<00:29,  8.92it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 12%|█▎        | 37/296 [00:03<00:28,  9.06it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 13%|█▎        | 38/296 [00:04<00:28,  9.18it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 13%|█▎        | 39/296 [00:04<01:23,  3.08it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 14%|█▎        | 40/296 [00:05<01:06,  3.85it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 14%|█▍        | 41/296 [00:05<00:54,  4.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 14%|█▍        | 42/296 [00:05<00:45,  5.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 15%|█▍        | 43/296 [00:05<00:40,  6.30it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 15%|█▍        | 44/296 [00:05<00:35,  7.01it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 15%|█▌        | 45/296 [00:05<00:32,  7.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 16%|█▌        | 46/296 [00:05<00:30,  8.12it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 16%|█▌        | 47/296 [00:05<00:30,  8.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 16%|█▌        | 48/296 [00:05<00:29,  8.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 17%|█▋        | 49/296 [00:05<00:28,  8.76it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 17%|█▋        | 50/296 [00:06<00:28,  8.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 17%|█▋        | 51/296 [00:06<00:28,  8.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 18%|█▊        | 52/296 [00:06<00:27,  9.00it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 18%|█▊        | 53/296 [00:06<00:26,  9.19it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 18%|█▊        | 54/296 [00:06<00:25,  9.33it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 19%|█▊        | 55/296 [00:06<00:27,  8.85it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 19%|█▉        | 56/296 [00:07<01:44,  2.29it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 19%|█▉        | 57/296 [00:07<01:20,  2.97it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 20%|█▉        | 58/296 [00:08<01:05,  3.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 20%|█▉        | 59/296 [00:08<00:52,  4.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 20%|██        | 60/296 [00:08<00:43,  5.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 21%|██        | 61/296 [00:08<00:37,  6.20it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 21%|██        | 62/296 [00:08<00:35,  6.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 21%|██▏       | 63/296 [00:08<00:31,  7.31it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 22%|██▏       | 64/296 [00:08<00:29,  7.88it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 22%|██▏       | 65/296 [00:08<00:27,  8.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 22%|██▏       | 66/296 [00:08<00:26,  8.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 23%|██▎       | 67/296 [00:09<00:25,  8.93it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 23%|██▎       | 68/296 [00:09<00:25,  9.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 23%|██▎       | 69/296 [00:09<00:24,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 24%|██▎       | 70/296 [00:09<00:24,  9.33it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 24%|██▍       | 71/296 [00:09<00:23,  9.43it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 24%|██▍       | 72/296 [00:09<00:23,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 25%|██▍       | 73/296 [00:09<00:23,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 25%|██▌       | 74/296 [00:09<00:23,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 25%|██▌       | 75/296 [00:09<00:24,  8.99it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 26%|██▌       | 76/296 [00:09<00:24,  9.14it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 26%|██▌       | 77/296 [00:10<00:23,  9.31it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 26%|██▋       | 78/296 [00:10<00:23,  9.41it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 27%|██▋       | 79/296 [00:10<00:22,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 27%|██▋       | 80/296 [00:10<00:22,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 27%|██▋       | 81/296 [00:10<00:22,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 28%|██▊       | 82/296 [00:10<00:22,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 28%|██▊       | 83/296 [00:10<00:22,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 28%|██▊       | 84/296 [00:10<00:22,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 29%|██▊       | 85/296 [00:10<00:21,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 29%|██▉       | 86/296 [00:11<00:21,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 29%|██▉       | 87/296 [00:11<00:21,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 30%|██▉       | 88/296 [00:11<00:21,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 30%|███       | 89/296 [00:11<00:21,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 30%|███       | 90/296 [00:11<00:21,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 31%|███       | 91/296 [00:11<00:22,  9.04it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 31%|███       | 92/296 [00:11<00:22,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 31%|███▏      | 93/296 [00:11<00:21,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 32%|███▏      | 94/296 [00:11<00:21,  9.44it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 32%|███▏      | 95/296 [00:11<00:21,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 32%|███▏      | 96/296 [00:12<00:21,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 33%|███▎      | 97/296 [00:12<00:20,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 33%|███▎      | 98/296 [00:12<00:20,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 33%|███▎      | 99/296 [00:12<00:20,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 34%|███▍      | 100/296 [00:12<00:20,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 34%|███▍      | 101/296 [00:12<00:20,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 34%|███▍      | 102/296 [00:12<00:20,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 35%|███▍      | 103/296 [00:12<00:20,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 35%|███▌      | 104/296 [00:12<00:20,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 35%|███▌      | 105/296 [00:13<00:19,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 36%|███▌      | 106/296 [00:13<00:19,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 36%|███▌      | 107/296 [00:13<00:21,  8.95it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 36%|███▋      | 108/296 [00:13<00:20,  9.16it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 37%|███▋      | 109/296 [00:13<00:20,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 37%|███▋      | 110/296 [00:13<00:19,  9.32it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 38%|███▊      | 111/296 [00:13<00:19,  9.43it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 38%|███▊      | 112/296 [00:13<00:19,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 38%|███▊      | 113/296 [00:13<00:19,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 39%|███▊      | 114/296 [00:13<00:19,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 39%|███▉      | 115/296 [00:14<00:18,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 39%|███▉      | 116/296 [00:14<00:18,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 40%|███▉      | 117/296 [00:14<00:18,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 40%|███▉      | 118/296 [00:14<00:18,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 40%|████      | 119/296 [00:14<00:18,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 41%|████      | 120/296 [00:14<00:19,  9.08it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 41%|████      | 121/296 [00:14<00:18,  9.24it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 41%|████      | 122/296 [00:14<00:18,  9.35it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 42%|████▏     | 123/296 [00:14<00:18,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 42%|████▏     | 124/296 [00:15<00:18,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 42%|████▏     | 125/296 [00:15<00:18,  9.50it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 43%|████▎     | 126/296 [00:15<00:17,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 43%|████▎     | 127/296 [00:15<00:17,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 43%|████▎     | 128/296 [00:15<00:17,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 44%|████▎     | 129/296 [00:15<00:17,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 44%|████▍     | 130/296 [00:15<00:17,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 44%|████▍     | 131/296 [00:15<00:17,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 45%|████▍     | 132/296 [00:15<00:17,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 45%|████▍     | 133/296 [00:15<00:17,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 45%|████▌     | 134/296 [00:16<00:16,  9.56it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 46%|████▌     | 135/296 [00:16<00:16,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 46%|████▌     | 136/296 [00:16<00:16,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 46%|████▋     | 137/296 [00:16<00:16,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 47%|████▋     | 138/296 [00:16<00:16,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 47%|████▋     | 139/296 [00:16<00:16,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 47%|████▋     | 140/296 [00:16<00:16,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 48%|████▊     | 141/296 [00:16<00:16,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 48%|████▊     | 142/296 [00:16<00:15,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 48%|████▊     | 143/296 [00:17<00:15,  9.70it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 49%|████▊     | 144/296 [00:17<00:15,  9.70it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 49%|████▉     | 145/296 [00:17<00:15,  9.71it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 49%|████▉     | 146/296 [00:17<00:15,  9.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 50%|████▉     | 147/296 [00:17<00:16,  9.16it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 50%|█████     | 148/296 [00:17<00:15,  9.34it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 50%|█████     | 149/296 [00:17<00:15,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 51%|█████     | 150/296 [00:17<00:15,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 51%|█████     | 151/296 [00:17<00:15,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 51%|█████▏    | 152/296 [00:17<00:14,  9.70it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 52%|█████▏    | 153/296 [00:18<00:14,  9.71it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 52%|█████▏    | 154/296 [00:18<00:15,  9.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 52%|█████▏    | 155/296 [00:18<00:15,  9.25it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 53%|█████▎    | 156/296 [00:18<00:14,  9.39it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 53%|█████▎    | 157/296 [00:18<00:14,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 53%|█████▎    | 158/296 [00:18<00:14,  9.57it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 54%|█████▎    | 159/296 [00:18<00:14,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 54%|█████▍    | 160/296 [00:18<00:14,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 54%|█████▍    | 161/296 [00:18<00:13,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 55%|█████▍    | 162/296 [00:19<00:13,  9.71it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 55%|█████▌    | 163/296 [00:19<00:13,  9.73it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 55%|█████▌    | 164/296 [00:19<00:13,  9.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 56%|█████▌    | 165/296 [00:19<00:13,  9.77it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 56%|█████▌    | 166/296 [00:19<00:14,  9.17it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 56%|█████▋    | 167/296 [00:19<00:14,  8.78it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 57%|█████▋    | 168/296 [00:19<00:14,  9.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 57%|█████▋    | 169/296 [00:19<00:13,  9.27it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 57%|█████▋    | 170/296 [00:19<00:13,  9.38it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 58%|█████▊    | 171/296 [00:19<00:13,  9.46it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 58%|█████▊    | 172/296 [00:20<00:13,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 58%|█████▊    | 173/296 [00:20<00:12,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 59%|█████▉    | 174/296 [00:20<00:12,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 59%|█████▉    | 175/296 [00:20<00:12,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 59%|█████▉    | 176/296 [00:20<00:12,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 60%|█████▉    | 177/296 [00:20<00:12,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 60%|██████    | 178/296 [00:20<00:12,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 60%|██████    | 179/296 [00:20<00:12,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 61%|██████    | 180/296 [00:20<00:11,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 61%|██████    | 181/296 [00:21<00:11,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 61%|██████▏   | 182/296 [00:21<00:11,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 62%|██████▏   | 183/296 [00:21<00:11,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 62%|██████▏   | 184/296 [00:21<00:11,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 62%|██████▎   | 185/296 [00:21<00:12,  9.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 63%|██████▎   | 186/296 [00:21<00:11,  9.22it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 63%|██████▎   | 187/296 [00:21<00:11,  9.37it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 64%|██████▎   | 188/296 [00:21<00:11,  9.47it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 64%|██████▍   | 189/296 [00:21<00:11,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 64%|██████▍   | 190/296 [00:21<00:11,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 65%|██████▍   | 191/296 [00:22<00:10,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 65%|██████▍   | 192/296 [00:22<00:10,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 65%|██████▌   | 193/296 [00:22<00:10,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 66%|██████▌   | 194/296 [00:22<00:10,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 66%|██████▌   | 195/296 [00:22<00:10,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 66%|██████▌   | 196/296 [00:22<00:10,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 67%|██████▋   | 197/296 [00:22<00:10,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 67%|██████▋   | 198/296 [00:22<00:10,  9.69it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 67%|██████▋   | 199/296 [00:22<00:09,  9.71it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 68%|██████▊   | 200/296 [00:23<00:09,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 68%|██████▊   | 201/296 [00:23<00:09,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 68%|██████▊   | 202/296 [00:23<00:09,  9.70it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 69%|██████▊   | 203/296 [00:23<00:09,  9.72it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 69%|██████▉   | 204/296 [00:23<00:09,  9.73it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 69%|██████▉   | 205/296 [00:23<00:09,  9.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 70%|██████▉   | 206/296 [00:23<00:09,  9.77it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 70%|██████▉   | 207/296 [00:23<00:09,  9.78it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 70%|███████   | 208/296 [00:23<00:09,  9.77it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 71%|███████   | 209/296 [00:23<00:08,  9.76it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 71%|███████   | 210/296 [00:24<00:08,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 71%|███████▏  | 211/296 [00:24<00:09,  9.10it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 72%|███████▏  | 212/296 [00:24<00:09,  8.75it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 72%|███████▏  | 213/296 [00:24<00:09,  9.03it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 72%|███████▏  | 214/296 [00:24<00:08,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 73%|███████▎  | 215/296 [00:24<00:08,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 73%|███████▎  | 216/296 [00:24<00:08,  9.49it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 73%|███████▎  | 217/296 [00:24<00:08,  8.99it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 74%|███████▎  | 218/296 [00:24<00:08,  9.21it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 74%|███████▍  | 219/296 [00:25<00:08,  8.82it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 74%|███████▍  | 220/296 [00:25<00:08,  9.04it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 75%|███████▍  | 221/296 [00:25<00:08,  9.22it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 75%|███████▌  | 222/296 [00:25<00:08,  8.82it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 75%|███████▌  | 223/296 [00:25<00:08,  9.07it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 76%|███████▌  | 224/296 [00:25<00:07,  9.18it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 76%|███████▌  | 225/296 [00:25<00:07,  9.36it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 76%|███████▋  | 226/296 [00:25<00:07,  9.40it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 77%|███████▋  | 227/296 [00:25<00:07,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 77%|███████▋  | 228/296 [00:25<00:07,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 77%|███████▋  | 229/296 [00:26<00:06,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 78%|███████▊  | 230/296 [00:26<00:06,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 78%|███████▊  | 231/296 [00:26<00:06,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 78%|███████▊  | 232/296 [00:26<00:06,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 79%|███████▊  | 233/296 [00:26<00:06,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 79%|███████▉  | 234/296 [00:26<00:06,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 79%|███████▉  | 235/296 [00:26<00:06,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 80%|███████▉  | 236/296 [00:26<00:06,  9.12it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 80%|████████  | 237/296 [00:26<00:06,  9.31it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 80%|████████  | 238/296 [00:27<00:06,  9.45it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 81%|████████  | 239/296 [00:27<00:05,  9.54it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 81%|████████  | 240/296 [00:27<00:05,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 81%|████████▏ | 241/296 [00:27<00:05,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 82%|████████▏ | 242/296 [00:27<00:05,  9.04it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 82%|████████▏ | 243/296 [00:27<00:05,  9.25it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 82%|████████▏ | 244/296 [00:27<00:05,  9.40it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 83%|████████▎ | 245/296 [00:27<00:05,  8.93it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 83%|████████▎ | 246/296 [00:27<00:05,  9.18it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 83%|████████▎ | 247/296 [00:28<00:05,  9.31it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 84%|████████▍ | 248/296 [00:28<00:05,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 84%|████████▍ | 249/296 [00:28<00:04,  9.53it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 84%|████████▍ | 250/296 [00:28<00:04,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 85%|████████▍ | 251/296 [00:28<00:04,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 85%|████████▌ | 252/296 [00:28<00:04,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 85%|████████▌ | 253/296 [00:28<00:04,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 86%|████████▌ | 254/296 [00:28<00:04,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 86%|████████▌ | 255/296 [00:28<00:04,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 86%|████████▋ | 256/296 [00:28<00:04,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 87%|████████▋ | 257/296 [00:29<00:04,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 87%|████████▋ | 258/296 [00:29<00:03,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 88%|████████▊ | 259/296 [00:29<00:03,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 88%|████████▊ | 260/296 [00:29<00:03,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 88%|████████▊ | 261/296 [00:29<00:03,  9.62it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 89%|████████▊ | 262/296 [00:29<00:03,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 89%|████████▉ | 263/296 [00:29<00:03,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 89%|████████▉ | 264/296 [00:29<00:03,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 90%|████████▉ | 265/296 [00:29<00:03,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 90%|████████▉ | 266/296 [00:29<00:03,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 90%|█████████ | 267/296 [00:30<00:02,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 91%|█████████ | 268/296 [00:30<00:02,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 91%|█████████ | 269/296 [00:30<00:02,  9.59it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 91%|█████████ | 270/296 [00:30<00:02,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 92%|█████████▏| 271/296 [00:30<00:02,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 92%|█████████▏| 272/296 [00:30<00:02,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 92%|█████████▏| 273/296 [00:30<00:02,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 93%|█████████▎| 274/296 [00:30<00:02,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 93%|█████████▎| 275/296 [00:30<00:02,  9.68it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 93%|█████████▎| 276/296 [00:31<00:02,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 94%|█████████▎| 277/296 [00:31<00:01,  9.63it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 94%|█████████▍| 278/296 [00:31<00:01,  9.64it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 94%|█████████▍| 279/296 [00:31<00:01,  9.65it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 95%|█████████▍| 280/296 [00:31<00:01,  9.66it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 95%|█████████▍| 281/296 [00:31<00:01,  9.67it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 95%|█████████▌| 282/296 [00:31<00:01,  9.09it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 96%|█████████▌| 283/296 [00:31<00:01,  9.27it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 96%|█████████▌| 284/296 [00:31<00:01,  9.38it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 96%|█████████▋| 285/296 [00:31<00:01,  9.42it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 97%|█████████▋| 286/296 [00:32<00:01,  9.51it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 97%|█████████▋| 287/296 [00:32<00:00,  9.58it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 97%|█████████▋| 288/296 [00:32<00:00,  9.52it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 98%|█████████▊| 289/296 [00:32<00:00,  9.48it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 98%|█████████▊| 290/296 [00:32<00:00,  9.55it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 98%|█████████▊| 291/296 [00:32<00:00,  9.60it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 99%|█████████▊| 292/296 [00:32<00:00,  9.61it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 99%|█████████▉| 293/296 [00:32<00:00,  9.05it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      " 99%|█████████▉| 294/296 [00:32<00:00,  9.23it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "100%|█████████▉| 295/296 [00:33<00:00,  9.37it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "100%|██████████| 296/296 [00:33<00:00,  8.93it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_data(output_filepath):\n",
    "    # df = pd.read_csv(data_filepath)\n",
    "    df = test_df\n",
    "    # df = df[:5]\n",
    "    \n",
    "    pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model_id,\n",
    "        model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    num_examples = 15 # number of shots in few-shot\n",
    "    # Loop over the DataFrame and pass the text to generate response\n",
    "    for index, row in tqdm(list(df.iterrows())):\n",
    "        prompt = create_prompt(row['Sentence'], num_examples)\n",
    "        model_response = generate_responses(prompt, pipeline)\n",
    "        # print(model_response)\n",
    "        generated_label = parse_response(model_response)\n",
    "\n",
    "        # veracity, explanation = parse_response(model_response)\n",
    "        \n",
    "        results.append({\n",
    "            'Sentence': row['Sentence'],\n",
    "            'Label': row['Tag'],\n",
    "            'Response': model_response,\n",
    "            'Gen_label': generated_label,\n",
    "            # 'Explanation': explanation\n",
    "        })\n",
    "        # break\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example file paths, replace with your actual paths\n",
    "# data_filepath = '/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/test.csv'\n",
    "output_filepath = '/data1/debajyoti/test/llms/data/humor'\n",
    "\n",
    "# Run the data processing\n",
    "result = process_data(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gen_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 2 takiye ki naukri main mera lakhon ka worl...</td>\n",
       "      <td>0</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Naam : Viv Richards\\nBaap ka naam : Master Di...</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sakshi Maharaj is BJP's Digvijaya Singh.</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj @British_Airways ki toh lag gayi bhai.\\nHa...</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghanta development hoga! Saare paise to electi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hum to Aam Aadmi hain ji, woh Megalomaniac hai...</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Neend nahi aati hai raaton mein?</td>\n",
       "      <td>0</td>\n",
       "      <td>Non-humor</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Ghar mein Bipasha Basu ki photo rakhne se bhoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V</td>\n",
       "      <td>0</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tu na ja mere baadshah ek waade ke liye, maa c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Humor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Label   Response  \\\n",
       "0    Is 2 takiye ki naukri main mera lakhon ka worl...      0      Humor   \n",
       "1    \"Naam : Viv Richards\\nBaap ka naam : Master Di...      1      Humor   \n",
       "2             Sakshi Maharaj is BJP's Digvijaya Singh.      1      Humor   \n",
       "3    Aaj @British_Airways ki toh lag gayi bhai.\\nHa...      1      Humor   \n",
       "4    Ghanta development hoga! Saare paise to electi...      1      Humor   \n",
       "..                                                 ...    ...        ...   \n",
       "291  Hum to Aam Aadmi hain ji, woh Megalomaniac hai...      1      Humor   \n",
       "292                   Neend nahi aati hai raaton mein?      0  Non-humor   \n",
       "293  Ghar mein Bipasha Basu ki photo rakhne se bhoo...      1      Humor   \n",
       "294    Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V      0      Humor   \n",
       "295  Tu na ja mere baadshah ek waade ke liye, maa c...      1      Humor   \n",
       "\n",
       "    Gen_label  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "..        ...  \n",
       "291         1  \n",
       "292         0  \n",
       "293         1  \n",
       "294         1  \n",
       "295         1  \n",
       "\n",
       "[296 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envcodemix",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
