{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/debajyoti/test/llms/envllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.5: Fast Gemma patching. Transformers = 4.46.2.\n",
      "   \\\\   /|    GPU: NVIDIA A100 80GB PCIe. Max memory: 79.154 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n",
      "Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n",
      "`config.hidden_activation` if you want to override this behaviour.\n",
      "See https://github.com/huggingface/transformers/pull/29402 for more details.\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:07<00:00,  1.13it/s]\n",
      "Unsloth: Will load Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0 as a legacy tokenizer.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False \n",
    "cache_dir = \"/data1/debajyoti/test/llms/models\"\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0\",\n",
    "    cache_dir = cache_dir,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "input_prompt = \"\"\"\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "input_text = input_prompt.format(\n",
    "        \"\"\"You are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not. Dont give output anything else.\n",
    "    If the 'Input' is sarcastic, you need to output your final 'Output' as 'sarcasm'. \n",
    "    If the 'Input' is non-sarcastic, you need to output your final 'Output' as 'Non-sarcasm'.\"\"\", # instruction\n",
    "        \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi chaltapic.twitter.com/bOLAEk0g4E\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "\n",
    "inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)\n",
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<bos>\\n### Instruction:\\nYou are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not. Dont give output anything else.\\n    If the 'Input' is sarcastic, you need to output your final 'Output' as 'sarcasm'. \\n    If the 'Input' is non-sarcastic, you need to output your final 'Output' as 'Non-sarcasm'.\\n\\n### Input:\\nChalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi chaltapic.twitter.com/bOLAEk0g4E\\n\\n### Response:\\nNon-sarcasm<eos>\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_text = input_prompt.format(\n",
    "#         \"\"\"You are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not. Dont give output anything else.\n",
    "#     If the 'Input' is sarcastic, you need to output your final 'Output' as 'Sarcasm'. \n",
    "#     If the 'Input' is non-sarcastic, you need to output your final 'Output' as 'Non-sarcasm'.\"\"\", # instruction\n",
    "#         \"What happens if Usain Bolt misses his bus? He waits for it at the next stop.\", # input\n",
    "#         \"\", # output - leave this blank for generation!\n",
    "#     )\n",
    "\n",
    "# inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)\n",
    "# response = tokenizer.batch_decode(outputs)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mera bhanja mujhe \"papa ka sala\" bulata hai......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aur aap a0ni politics karne me vyast hai.. #Bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theek hai waha at least Janki ma ka mandir hai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir mujhe cricket acdemy join karna hai mai ka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>aaj bjp aur chadhi gang aise khus ho rahe hai ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>@SGanguly99 sir aapnio jodi aamar saath na den...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>#Irony: Pran ka pran chala gaya.. RIP Sher Khan!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Ye bhi mat bhulo ki triple talaq ko ban lagane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>#ViruPanti @virendersehwag @cricketaakash DHON...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Tag\n",
       "0    Mera bhanja mujhe \"papa ka sala\" bulata hai......    0\n",
       "1    Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...    0\n",
       "2    aur aap a0ni politics karne me vyast hai.. #Bi...    0\n",
       "3    Theek hai waha at least Janki ma ka mandir hai...    0\n",
       "4    Sir mujhe cricket acdemy join karna hai mai ka...    0\n",
       "..                                                 ...  ...\n",
       "520  aaj bjp aur chadhi gang aise khus ho rahe hai ...    0\n",
       "521  @SGanguly99 sir aapnio jodi aamar saath na den...    0\n",
       "522   #Irony: Pran ka pran chala gaya.. RIP Sher Khan!    1\n",
       "523  Ye bhi mat bhulo ki triple talaq ko ban lagane...    0\n",
       "524  #ViruPanti @virendersehwag @cricketaakash DHON...    0\n",
       "\n",
       "[525 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_eng = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Sarcasm_English.csv\")\n",
    "train_df_eng = train_df_eng[:2000]\n",
    "train_df_hin = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/New_Sarcasm_Hindi.csv\")\n",
    "train_df_hin = train_df_hin[:2000]\n",
    "train_df = pd.concat([train_df_eng, train_df_hin], ignore_index=True)\n",
    "# train_df = train_df_hin\n",
    "# train_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Sarcasm_Codemix.csv\")\n",
    "val_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/val.csv\")\n",
    "test_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/test.csv\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tag\n",
       "0    475\n",
       "1     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['Tag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§ñ‡§æ‡§®‡§æ‡§¨‡§¶‡•ã‡§∂ ‡§ö‡§∞‡§µ‡§æ‡§π‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§Ü‡§™ ‡§ú‡§æ‡§®‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§π‡•á‡§≤‡•ç‡§•‡§ï‡•á‡§Ø‡§∞ ‡§∏‡§ø...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§ó‡§≤‡§§- ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§ë‡§≤‡§∏‡•á‡§® ‡§â‡§® ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§π‡§µ‡§æ‡§≤‡§æ ‡§¶...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Well that may be your contention, but medicall...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence          Tag\n",
       "0  ‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§ñ‡§æ‡§®‡§æ‡§¨‡§¶‡•ã‡§∂ ‡§ö‡§∞‡§µ‡§æ‡§π‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç...  Non-sarcasm\n",
       "1  ‡§Ü‡§™ ‡§ú‡§æ‡§®‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§π‡•á‡§≤‡•ç‡§•‡§ï‡•á‡§Ø‡§∞ ‡§∏‡§ø...  Non-sarcasm\n",
       "2  ‡§ó‡§≤‡§§- ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§ë‡§≤‡§∏‡•á‡§® ‡§â‡§® ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§π‡§µ‡§æ‡§≤‡§æ ‡§¶...  Non-sarcasm\n",
       "3  Well that may be your contention, but medicall...  Non-sarcasm"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/sarcasm/few_shots/iacv2_hin_eng_llama.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§ñ‡§æ‡§®‡§æ‡§¨‡§¶‡•ã‡§∂ ‡§ö‡§∞‡§µ‡§æ‡§π‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§∞‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§∞‡§ñ‡•á‡§Ç?‡§Ø‡§π ‡§ï‡•Å‡§õ ‡§ú‡§æ‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§§‡§∞‡•ç‡§ï‡§∏‡§Ç‡§ó‡§§ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§®‡§ú‡§æ‡§®‡•á ‡§ú‡§æ‡§¶‡•Ç ‡§π‡•à, ‡§ú‡§ø‡§∏‡§®‡•á ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡§æ ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§∏‡§≠‡•Ä ‡§∏‡§¨‡•Ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡§®‡§æ‡§Ø‡§æ, ‡§§‡§æ‡§ï‡§ø ‡§µ‡§π ‡§ê‡§∏‡§æ ‡§π‡•ã ‡§ú‡•à‡§∏‡•á ‡§â‡§∏‡§®‡•á ‡§ê‡§∏‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ‡•§'},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§Ü‡§™ ‡§ú‡§æ‡§®‡§§‡•á ‡§π‡•à‡§Ç ‡§ï‡§ø ‡§Ö‡§ß‡§ø‡§ï‡§æ‡§Ç‡§∂ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§π‡•á‡§≤‡•ç‡§•‡§ï‡•á‡§Ø‡§∞ ‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§ï‡•á ‡§§‡§π‡§§ ‡§Ü‡§™ ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§®‡§ø‡§ú‡•Ä ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§ñ‡§∞‡•Ä‡§¶ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç ‡§Ø‡§¶‡§ø ‡§Ü‡§™ ‡§µ‡§æ‡§∏‡•ç‡§§‡§µ ‡§Æ‡•á‡§Ç ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç, ‡§§‡•ã ‡§Ü‡§™ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡§Ç? ‡§ú‡•à‡§∏‡§æ ‡§ï‡§ø ‡§ì‡§≤‡•ç‡§°‡§∏‡§∞‡•ç‡§ú ‡§ï‡•á ‡§¨‡•Ä‡§® ‡§™‡•Å‡§∂‡§∞‡•ç‡§∏ ‡§ï‡•á ‡§¶‡§æ‡§µ‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π ‡§§‡§Ø ‡§ï‡§∞‡§®‡§æ ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§¶‡•á‡§ñ‡§≠‡§æ‡§≤ ‡§Æ‡§ø‡§≤‡§§‡•Ä ‡§π‡•à, ‡§â‡§®‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡•Ç‡§∏‡§∞‡§æ ‡§®‡§æ‡§Æ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à \"‡§¶‡§æ‡§µ‡•á ‡§∏‡§Æ‡§æ‡§Ø‡•ã‡§ú‡§ï\"?‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§°‡•â‡§ï‡•ç‡§ü‡§∞ ‡§ï‡•ã ‡§¶‡•á‡§ñ‡§®‡•á ‡§ú‡§æ‡§§‡§æ ‡§π‡•Ç‡§Ç ‡§§‡•ã ‡§µ‡§π ‡§µ‡§π‡•Ä ‡§π‡•ã‡§§‡§æ ‡§π‡•à ‡§ú‡•ã ‡§Æ‡•á‡§∞‡§æ ‡§á‡§≤‡§æ‡§ú ‡§§‡§Ø ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ï‡§ø‡§∏‡•Ä ‡§î‡§∞ ‡§ï‡•ã ‡§®‡§π‡•Ä‡§Ç‡•§‡§â‡§∏‡•á ‡§´‡§Ç‡§°‡§ø‡§Ç‡§ó ‡§ï‡•Ä ‡§ú‡§æ‡§Ç‡§ö ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•ã ‡§≠‡•Ä ‡§ï‡•â‡§≤ ‡§ï‡§∞‡§®‡•á ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§Ö‡§ó‡§∞ ‡§Ø‡§π ‡§ï‡§ø‡§∏‡•Ä ‡§ï‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡§µ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, ‡§§‡•ã ‡§Ø‡§π ‡§Æ‡•á‡§∞‡•á ‡§≤‡§ø‡§è ‡§≠‡•Ä ‡§ï‡§µ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§'},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§ó‡§≤‡§§- ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§ë‡§≤‡§∏‡•á‡§® ‡§â‡§® ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§ï‡§æ ‡§π‡§µ‡§æ‡§≤‡§æ ‡§¶‡•á‡§§‡•á ‡§π‡•Å‡§è ‡§¨‡§π‡•Å‡§§ ‡§µ‡§ø‡§∂‡§ø‡§∑‡•ç‡§ü ‡§π‡•à, ‡§ú‡•ã ‡§â‡§®‡•ç‡§π‡•á‡§Ç ‡§≤‡§ó‡§§‡§æ ‡§π‡•à ‡§ï‡§ø ‡§á‡§∏ ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§Æ‡•á‡§Ç ‡§®‡§ø‡§∂‡§æ‡§® ‡§ï‡•ã ‡§ñ‡§§‡•ç‡§Æ ‡§ï‡§∞ ‡§¶‡§ø‡§Ø‡§æ ‡§π‡•à‡•§‡§µ‡§π ‡§è‡§ï ‡§≤‡§ø‡§Ç‡§ï ‡§ï‡•Ä ‡§∏‡§Ç‡§≠‡§æ‡§µ‡§®‡§æ ‡§™‡§∞ ‡§∂‡§æ‡§∏‡§® ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à- ‡§µ‡§π (‡§∏‡§π‡•Ä ‡§∞‡•Ç‡§™ ‡§∏‡•á IMO) ‡§ï‡•Å‡§õ ‡§∂‡•ç‡§∞‡§Æ‡§ø‡§ï‡•ã‡§Ç ‡§î‡§∞ ‡§™‡•ç‡§∞‡§ï‡§æ‡§∂‡§®‡•ã‡§Ç ‡§ï‡•ã ‡§≤‡§ï‡•ç‡§∑‡§ø‡§§ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•à‡•§'},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': 'Well that may be your contention, but medically that is not necessarily true. Maybe being gay doesn\\'t mean you are suicidal or depressed, but there is more of it going on in the gay life than in the hetero. That in itself is a wake up call. Depression and suicide are harmful, even if it doesn\\'t touch you personally. If it were as simple as you say the APA wouldn\\'t be re-evaluating \"reorientation therapies\" would they and with positive critiques too. You wouldn\\'t have prominent gay activists like Camile Paglia deriding the gay community for being malcontent when those unhappy with being gay seek and desire the way to be hetero.'},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'}]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to specified format\n",
    "formatted_few_shot_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted_few_shot_examples.append({'role': 'user', 'content': row['Sentence']})\n",
    "    formatted_few_shot_examples.append({'role': 'assistant', 'content': row['Tag']})\n",
    "    \n",
    "formatted_few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input': \"‡§î‡§∞ ‡§á‡§∏‡§ï‡•á ‡§¨‡§ú‡§æ‡§Ø ‡§ñ‡§æ‡§®‡§æ‡§¨‡§¶‡•ã‡§∂ ‡§ö‡§∞‡§µ‡§æ‡§π‡•ã‡§Ç ‡§ï‡•Ä ‡§™‡•å‡§∞‡§æ‡§£‡§ø‡§ï ‡§ï‡§•‡§æ‡§ì‡§Ç ‡§Æ‡•á‡§Ç ‡§Æ‡•á‡§∞‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏ ‡§∞‡§ñ‡•á‡§Ç?‡§Ø‡§π ‡§ï‡•Å‡§õ ‡§ú‡§æ‡§®‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§§‡§∞‡•ç‡§ï‡§∏‡§Ç‡§ó‡§§ ‡§π‡•à, ‡§≤‡•á‡§ï‡§ø‡§® ‡§Ö‡§®‡§ú‡§æ‡§®‡•á ‡§ú‡§æ‡§¶‡•Ç ‡§π‡•à, ‡§ú‡§ø‡§∏‡§®‡•á ‡§∏‡§¨ ‡§ï‡•Å‡§õ ‡§Ö‡§∏‡•ç‡§§‡§ø‡§§‡•ç‡§µ ‡§Æ‡•á‡§Ç ‡§∞‡§ñ‡§æ ‡§î‡§∞ ‡§´‡§ø‡§∞ ‡§∏‡§≠‡•Ä ‡§∏‡§¨‡•Ç‡§§‡•ã‡§Ç ‡§ï‡•ã ‡§¨‡§®‡§æ‡§Ø‡§æ, ‡§§‡§æ‡§ï‡§ø ‡§µ‡§π ‡§ê‡§∏‡§æ ‡§π‡•ã ‡§ú‡•à‡§∏‡•á ‡§â‡§∏‡§®‡•á ‡§ê‡§∏‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ï‡§ø‡§Ø‡§æ‡•§\"\n",
      "'Response':\"Non-sarcasm\"\n",
      "\n",
      "'Input': \"Well that may be your contention, but medically that is not necessarily true. Maybe being gay doesn't mean you are suicidal or depressed, but there is more of it going on in the gay life than in the hetero. That in itself is a wake up call. Depression and suicide are harmful, even if it doesn't touch you personally. If it were as simple as you say the APA wouldn't be re-evaluating \"reorientation therapies\" would they and with positive critiques too. You wouldn't have prominent gay activists like Camile Paglia deriding the gay community for being malcontent when those unhappy with being gay seek and desire the way to be hetero.\"\n",
      "'Response':\"Non-sarcasm\"\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "formatted_few_shot_examples = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    if index == 0 or index == 3:\n",
    "        formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    # formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    # if index == 1:\n",
    "    #     break\n",
    "\n",
    "# Display the result\n",
    "print(formatted_few_shot_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt, parse response and  generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the function to create the prompt\n",
    "def create_prompt(input, num_examples):\n",
    "\n",
    "    # System prompt \n",
    "    system_prompt = \"\"\"You are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not.\n",
    "        If the 'Input' is sarcastic, you need to give your final 'Output' as \"Sarcasm\". \n",
    "        If the 'Input' is non-sarcastic, you need to give your final 'Output' as \"Non-sarcasm\". Dont output anything else. \"\"\"\n",
    "\n",
    "    messages = [system_prompt + formatted_few_shot_examples, input]\n",
    "    # messages = [system_prompt, input]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def parse_response(response):\n",
    "    \"\"\"\n",
    "    Extracts the classification label and explanation from the model-generated response,\n",
    "    starting from the line containing the final \"Answer:\".\n",
    "\n",
    "    Args:\n",
    "        response (str): The response generated by the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the classification label (\"Sarcasm\" or \"Non-sarcasm\") \n",
    "               and the explanation text.\n",
    "    \"\"\"\n",
    "    # print(response)\n",
    "    if len(response) > 0:        \n",
    "        if \"Non-sarcasm\" in response:\n",
    "            return \"0\"\n",
    "        elif \"Sarcasm\" in response:\n",
    "            return \"1\"\n",
    "        else:# If no label is found, return None\n",
    "            return None\n",
    "\n",
    "def generate_responses(prompt):\n",
    "    \n",
    "    input_prompt = \"\"\"\n",
    "    ### Instruction:\n",
    "    {}\n",
    "\n",
    "    ### Input:\n",
    "    {}\n",
    "\n",
    "    ### Response:\n",
    "    {}\"\"\"\n",
    "\n",
    "    input_text = input_prompt.format(\n",
    "            f\"\"\"{prompt[0]}\"\"\", # instruction\n",
    "            f\"{prompt[1]}\", # input\n",
    "            \"\", # output - leave this blank for generation!\n",
    "        )\n",
    "\n",
    "    inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 400, use_cache = True)\n",
    "    response = tokenizer.batch_decode(outputs)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/525 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 525/525 [02:41<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_data(data_filepath, output_filepath):\n",
    "    # df = pd.read_csv(data_filepath)\n",
    "    df = test_df\n",
    "    # df = df[:5]\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    num_examples = 15 # number of shots in few-shot\n",
    "    # Loop over the DataFrame and pass the text to generate response\n",
    "    for index, row in tqdm(list(df.iterrows())):\n",
    "        prompt = create_prompt(row['Sentence'], num_examples)\n",
    "        model_response = generate_responses(prompt)\n",
    "        # print(model_response)\n",
    "        generated_label = parse_response(model_response)\n",
    "\n",
    "        # veracity, explanation = parse_response(model_response)\n",
    "        \n",
    "        results.append({\n",
    "            'Sentence': row['Sentence'],\n",
    "            'Label': row['Tag'],\n",
    "            'Response': model_response,\n",
    "            'Gen_label': generated_label,\n",
    "            # 'Explanation': explanation\n",
    "        })\n",
    "        # break\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example file paths, replace with your actual paths\n",
    "data_filepath = '/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/test.csv'\n",
    "output_filepath = '/data1/debajyoti/test/llms/data/humor'\n",
    "\n",
    "# Run the data processing\n",
    "result = process_data(data_filepath, output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gen_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mera bhanja mujhe \"papa ka sala\" bulata hai......</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aur aap a0ni politics karne me vyast hai.. #Bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theek hai waha at least Janki ma ka mandir hai...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir mujhe cricket acdemy join karna hai mai ka...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>aaj bjp aur chadhi gang aise khus ho rahe hai ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>@SGanguly99 sir aapnio jodi aamar saath na den...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>#Irony: Pran ka pran chala gaya.. RIP Sher Khan!</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Ye bhi mat bhulo ki triple talaq ko ban lagane...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>#ViruPanti @virendersehwag @cricketaakash DHON...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a sa...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Label  \\\n",
       "0    Mera bhanja mujhe \"papa ka sala\" bulata hai......      0   \n",
       "1    Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...      0   \n",
       "2    aur aap a0ni politics karne me vyast hai.. #Bi...      0   \n",
       "3    Theek hai waha at least Janki ma ka mandir hai...      0   \n",
       "4    Sir mujhe cricket acdemy join karna hai mai ka...      0   \n",
       "..                                                 ...    ...   \n",
       "520  aaj bjp aur chadhi gang aise khus ho rahe hai ...      0   \n",
       "521  @SGanguly99 sir aapnio jodi aamar saath na den...      0   \n",
       "522   #Irony: Pran ka pran chala gaya.. RIP Sher Khan!      1   \n",
       "523  Ye bhi mat bhulo ki triple talaq ko ban lagane...      0   \n",
       "524  #ViruPanti @virendersehwag @cricketaakash DHON...      0   \n",
       "\n",
       "                                              Response Gen_label  \n",
       "0    [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "1    [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "2    [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "3    [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "4    [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "..                                                 ...       ...  \n",
       "520  [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "521  [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "522  [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "523  [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "524  [<bos>\\n    ### Instruction:\\n    You are a sa...      None  \n",
       "\n",
       "[525 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Label: Humor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1148884/2053982226.py:21: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  @validator('output_label', pre=True, always=True)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "import re\n",
    "\n",
    "class ModelResponse(BaseModel):\n",
    "    instruction: str\n",
    "    input_text: str\n",
    "    output_label: str\n",
    "\n",
    "    # @validator('instruction', pre=True, always=True)\n",
    "    # def extract_instruction(cls, value, values):\n",
    "    #     # Extract the Instruction part\n",
    "    #     match = re.search(r'### Instruction:\\n(.+?)\\n\\n### Input:', value, re.DOTALL)\n",
    "    #     return match.group(1).strip() if match else \"\"\n",
    "\n",
    "    # @validator('input_text', pre=True, always=True)\n",
    "    # def extract_input_text(cls, value, values):\n",
    "    #     # Extract the Input part\n",
    "    #     match = re.search(r'### Input:\\n(.+?)\\n\\n### Response:', value, re.DOTALL)\n",
    "    #     return match.group(1).strip() if match else \"\"\n",
    "\n",
    "    @validator('output_label', pre=True, always=True)\n",
    "    def extract_output_label(cls, value, values):\n",
    "        # Extract the Response part\n",
    "        match = re.search(r'### Response:\\n(.+?)<eos>', value, re.DOTALL)\n",
    "        return match.group(1).strip() if match else \"\"\n",
    "\n",
    "# Example usage\n",
    "response_text = (\n",
    "    \"<bos>\\n### Instruction:\\nYou are a sarcasm recognition assistant judging if an 'Input' \"\n",
    "    \"is sarcastic or not. Dont give output anything else.\\n    If the 'Input' is sarcastic, \"\n",
    "    \"you need to output your final 'Output' as 'Sarcasm'. \\n    If the 'Input' is non-sarcastic, \"\n",
    "    \"you need to output your final 'Output' as 'Non-sarcasm'.\\n\\n### Input:\\nWhat happens if Usain Bolt \"\n",
    "    \"misses his bus? He waits for it at the next stop.\\n\\n### Response:\\nHumor<eos>\"\n",
    ")\n",
    "\n",
    "# Create ModelResponse object\n",
    "parsed_response = ModelResponse(instruction=response_text, input_text=response_text, output_label=response_text)\n",
    "\n",
    "# Access parsed fields\n",
    "# print(\"Instruction:\", parsed_response.instruction)\n",
    "# print(\"Input Text:\", parsed_response.input_text)\n",
    "print(\"Output Label:\", parsed_response.output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(list(result.iterrows())):\n",
    "    parsed_response = ModelResponse(instruction=row['Response'][0], input_text=row['Response'][0], output_label=row['Response'][0])\n",
    "\n",
    "    # Access parsed fields\n",
    "    print(\"Output Label:\", parsed_response.output_label)\n",
    "    result['Gen_label'][index] = parsed_response.output_label\n",
    "    print(result['Gen_label'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Gen_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the Gen_label column values\n",
    "result['Gen_label'] = result['Gen_label'].str.replace(r'\\W', '', regex=True).str.lower()\n",
    "\n",
    "# Map the standardized labels to the final desired labels\n",
    "result['Gen_label'] = result['Gen_label'].map({\n",
    "    'nonsarcasm': 'Non-sarcasm',\n",
    "    'sarcasm': 'Sarcasm'\n",
    "})\n",
    "\n",
    "# Check the updated value counts\n",
    "print(result['Gen_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map string labels to integers\n",
    "label_mapping = {'Non-sarcasm': 0, 'Sarcasm': 1}\n",
    "new_result['Gen_label'] = new_result['Gen_label'].map(label_mapping)\n",
    "\n",
    "# Check the result\n",
    "print(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(map(int, new_result['Label']))\n",
    "y_pred = list(map(int, new_result['Gen_label']))\n",
    "print(classification_report(y_true, y_pred, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
