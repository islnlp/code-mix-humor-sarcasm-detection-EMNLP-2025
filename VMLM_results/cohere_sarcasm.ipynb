{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/debajyoti/test/llms/envllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,TrainingArguments\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = True\n",
    "if USE_GPU:\n",
    "    device = \"cuda:0\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "\n",
    "# you may want to change the following parameters depending on your GPU configuration\n",
    "\n",
    "# free T4 instance\n",
    "# QUANTIZE_4BIT = True\n",
    "# USE_GRAD_CHECKPOINTING = True\n",
    "# TRAIN_BATCH_SIZE = 2\n",
    "# TRAIN_MAX_SEQ_LENGTH = 512\n",
    "# USE_FLASH_ATTENTION = False\n",
    "# GRAD_ACC_STEPS = 16\n",
    "\n",
    "# equivalent A100 setting\n",
    "QUANTIZE_4BIT = True\n",
    "USE_GRAD_CHECKPOINTING = True\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "TRAIN_MAX_SEQ_LENGTH = 512\n",
    "USE_FLASH_ATTENTION = True\n",
    "GRAD_ACC_STEPS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"CohereForAI/aya-expanse-8b\"\n",
    "models_path = \"/data1/debajyoti/test/llms/models/\"\n",
    "\n",
    "attn_implementation = None\n",
    "if USE_FLASH_ATTENTION:\n",
    "  attn_implementation=\"flash_attention_2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          MODEL_NAME,\n",
    "          attn_implementation=attn_implementation,\n",
    "          torch_dtype=torch.bfloat16,\n",
    "          cache_dir=models_path,\n",
    "          device_map=\"auto\"\n",
    "        )\n",
    "# model = model.to(device)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_format(prompts):\n",
    "  messages = []\n",
    "\n",
    "  for p in prompts:\n",
    "    messages.append(\n",
    "          [{\"role\": \"system\", \"content\": \"\"\"You are a sarcasm recognition assistant judging if an 'Input' is sarcastic or not. No need to consider any prior context.\n",
    "            If the 'Input' is sarcastic, you need to output your final 'Output' as 'Sarcasm'. \n",
    "            If the 'Input' is non-sarcastic, you need to output your final 'Output' as 'Non-sarcasm'.\"\"\"},\n",
    "          {\"role\": \"user\", \"content\": p}]\n",
    "      )\n",
    "\n",
    "  return messages\n",
    "\n",
    "def generate_aya(\n",
    "      model,\n",
    "      prompts,\n",
    "      temperature=0.75,\n",
    "      top_p=1.0,\n",
    "      top_k=0,\n",
    "      max_new_tokens=1024\n",
    "    ):\n",
    "\n",
    "  # print(prompts)\n",
    "  messages = get_message_format(prompts)\n",
    "  # print(messages)\n",
    "\n",
    "  input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "      )\n",
    "  input_ids = input_ids.to(model.device)\n",
    "  prompt_padded_len = len(input_ids[0])\n",
    "\n",
    "  gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "      )\n",
    "\n",
    "  # get only generated tokens\n",
    "  gen_tokens = [\n",
    "      gt[prompt_padded_len:] for gt in gen_tokens\n",
    "    ]\n",
    "\n",
    "  gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "  return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT\n",
      "Input: \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi\" \n",
      "    Output: \n",
      "RESPONSE\n",
      "Output: Sarcasm\n",
      "\n",
      "The statement implies that if the Vice President were not Muslim, the protocol issue would have never been identified or addressed. This suggests a sarcastic tone, implying that the speaker is making a joke or pointing out a prejudiced or ignorant comment.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test generations on langauges in Aya 23 set\n",
    "prompts = [\n",
    "    \"\"\"Input: \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi\" \n",
    "    Output: \"\"\"\n",
    "]\n",
    "\n",
    "generations = generate_aya(model, prompts)\n",
    "\n",
    "for p, g in zip(prompts, generations):\n",
    "  print(\n",
    "      \"PROMPT\", p ,\"RESPONSE\", g, \"\\n\", sep=\"\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mera bhanja mujhe \"papa ka sala\" bulata hai......</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aur aap a0ni politics karne me vyast hai.. #Bi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theek hai waha at least Janki ma ka mandir hai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir mujhe cricket acdemy join karna hai mai ka...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>aaj bjp aur chadhi gang aise khus ho rahe hai ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>@SGanguly99 sir aapnio jodi aamar saath na den...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>#Irony: Pran ka pran chala gaya.. RIP Sher Khan!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Ye bhi mat bhulo ki triple talaq ko ban lagane...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>#ViruPanti @virendersehwag @cricketaakash DHON...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Tag\n",
       "0    Mera bhanja mujhe \"papa ka sala\" bulata hai......    0\n",
       "1    Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...    0\n",
       "2    aur aap a0ni politics karne me vyast hai.. #Bi...    0\n",
       "3    Theek hai waha at least Janki ma ka mandir hai...    0\n",
       "4    Sir mujhe cricket acdemy join karna hai mai ka...    0\n",
       "..                                                 ...  ...\n",
       "520  aaj bjp aur chadhi gang aise khus ho rahe hai ...    0\n",
       "521  @SGanguly99 sir aapnio jodi aamar saath na den...    0\n",
       "522   #Irony: Pran ka pran chala gaya.. RIP Sher Khan!    1\n",
       "523  Ye bhi mat bhulo ki triple talaq ko ban lagane...    0\n",
       "524  #ViruPanti @virendersehwag @cricketaakash DHON...    0\n",
       "\n",
       "[525 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/train.csv\")\n",
    "val_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/val.csv\")\n",
    "test_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/sarcasm/test.csv\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thats where you are wrong ..again.\\r\\nAsk your...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Right so...1) God will kill you before he give...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And lets not neglect the fact that he was teto...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Because, not once, did I have feel any sort of...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A tenth grade education? Why am I not surprise...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I will stop quoting here. Don't want people to...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oh yes liberal: anyone who disagrees with vor ...</td>\n",
       "      <td>Sarcasm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jp: you keep spouting the same inaccuracy. i h...</td>\n",
       "      <td>Non-sarcasm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence          Tag\n",
       "0  Thats where you are wrong ..again.\\r\\nAsk your...      Sarcasm\n",
       "1  Right so...1) God will kill you before he give...  Non-sarcasm\n",
       "2  And lets not neglect the fact that he was teto...      Sarcasm\n",
       "3  Because, not once, did I have feel any sort of...  Non-sarcasm\n",
       "4  A tenth grade education? Why am I not surprise...      Sarcasm\n",
       "5  I will stop quoting here. Don't want people to...  Non-sarcasm\n",
       "6  oh yes liberal: anyone who disagrees with vor ...      Sarcasm\n",
       "7  jp: you keep spouting the same inaccuracy. i h...  Non-sarcasm"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/sarcasm/few_shots/iacv2_eng_llama.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Thats where you are wrong ..again.\\r\\nAsk your friend poet what jebus would do.I havent a clue.\\r\\nYou seem to be frustrated though......is it because you cannot find evidence that I defended ID but dont have the nuts to admit it?'},\n",
       " {'role': 'assistant', 'content': 'Sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': \"Right so...1) God will kill you before he gives you a chance to repent? Thus sending you straight to hell. I like that!2) God seems to make life unfair for most everyone. Hey, even in America. Consider in America, and extrememly religious state, you still have the highest homocide rates out of ALL the western countries. (I'm pretty sure of this.)3) Left behind? So, wait. The riegtous go the heaven, and everyone else remains leading a normal, religion free life on earth? Hmmm...4) Hebrews?5) Can it help? The gospels tell a story about a carpenter who lived 2000 years ago, and may or may not have been the son of god. Yeah, I can see how that can help. Why can't I worship the Flying Spaghetti Monster?\"},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': \"And lets not neglect the fact that he was tetotal and a vegetarian to boot.\\r\\nWell, looky here we all learnt today that bad people can have have good characteristics............\\r\\nSounds like Pastor Russell Johnson's representation of truth is as selective as it is self serving.\"},\n",
       " {'role': 'assistant', 'content': 'Sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': \"Because, not once, did I have feel any sort of physical attraction to the same gender as myself. I have known other people who have. I don't 'CHOOSE' who I think is sexually attractive. It might have been environmental, but it certainly wasn't a 'choice'I have to assume that at least for some , if not most homosexuals, that pattern repeats itself.\"},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': \"A tenth grade education? Why am I not surprised. That explains why you swallow this evo dung, because it makes you feel smart and enlightened. It is the most popular form of intellectual masturbation for the uninformed and pseudo intellectual today; not to mention the religion of the Natural Man. And here's a clue for you buddy, don't believe everything you read on the internet. Try using common sense before swallowing this tripe and if you want to exercise your common sense muscle, go back and reread all of my posts and try to answer all of my questions objectively. You know, those questions that you and every one of your compadres have completely ignored and not attempted to directly answer at all.\"},\n",
       " {'role': 'assistant', 'content': 'Sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': \"I will stop quoting here. Don't want people to have too big a read. Actually ToE isn't all that random. To a certain degree yes. But Sexual Selection aka a part of the ToE. Dictates that when there is a benificial/attractive change. That change will be enhanced almost exponentially. Because the female of the species will be programmed to search for that and will carry the gene herself so will give it to her off spring. And the male will be more succesfull so produce more off spring. So no instant eyes or anything like that. I think that's what you were implying. Sorry for responding in Kronus's stead. I'm sure he can defend himself but I found it unjust the way you replied to his post and attacked it on foundations that you didn't have.\"},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': \"oh yes liberal: anyone who disagrees with vor regardless of their political standing. you would call frist a liberal if he disagreed with you, hell you would even goldwater a liberal if he disagreed with you.  i'm going to mentally replace farfignewgin whenever you say liberal, after all, they have the same meaning in your context.  you can support the troops by disagreeing with any mission that is unncessary in terms of security and any mission that puts troops in unncessary danger. explain to me how you can support the troops by supporting a mission that doesn't help america and gets 1600 of them needlessly killed.\"},\n",
       " {'role': 'assistant', 'content': 'Sarcasm'},\n",
       " {'role': 'user',\n",
       "  'content': 'jp: you keep spouting the same inaccuracy. i have already given you the cornell law schools definition and explanation of the impeachment process. do you need harvard and dukes as well? the house brought a resolution of impeachment. the senate denied it. the house resolution is similar to an indictment. the senate denial is similar to a not guilty verdict. your need to distort demeans you. really? who are you, carnack the magnificent? you can tell what would happen. richard nixon resigned and his offense was not as serious for the national security as the underlying offense is for libby. bottom line is you dont know what would happen. nobody does. but is does reveal that the only basis for you erroneous rhetoric is your speculation and distortion..'},\n",
       " {'role': 'assistant', 'content': 'Non-sarcasm'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to specified format\n",
    "formatted_few_shot_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted_few_shot_examples.append({'role': 'user', 'content': row['Sentence']})\n",
    "    formatted_few_shot_examples.append({'role': 'assistant', 'content': row['Tag']})\n",
    "    \n",
    "formatted_few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input': \"Thats where you are wrong ..again.\n",
      "Ask your friend poet what jebus would do.I havent a clue.\n",
      "You seem to be frustrated though......is it because you cannot find evidence that I defended ID but dont have the nuts to admit it?\"\n",
      "'Response':\"Sarcasm\"\n",
      "\n",
      "'Input': \"Right so...1) God will kill you before he gives you a chance to repent? Thus sending you straight to hell. I like that!2) God seems to make life unfair for most everyone. Hey, even in America. Consider in America, and extrememly religious state, you still have the highest homocide rates out of ALL the western countries. (I'm pretty sure of this.)3) Left behind? So, wait. The riegtous go the heaven, and everyone else remains leading a normal, religion free life on earth? Hmmm...4) Hebrews?5) Can it help? The gospels tell a story about a carpenter who lived 2000 years ago, and may or may not have been the son of god. Yeah, I can see how that can help. Why can't I worship the Flying Spaghetti Monster?\"\n",
      "'Response':\"Non-sarcasm\"\n",
      "\n",
      "'Input': \"And lets not neglect the fact that he was tetotal and a vegetarian to boot.\n",
      "Well, looky here we all learnt today that bad people can have have good characteristics............\n",
      "Sounds like Pastor Russell Johnson's representation of truth is as selective as it is self serving.\"\n",
      "'Response':\"Sarcasm\"\n",
      "\n",
      "'Input': \"Because, not once, did I have feel any sort of physical attraction to the same gender as myself. I have known other people who have. I don't 'CHOOSE' who I think is sexually attractive. It might have been environmental, but it certainly wasn't a 'choice'I have to assume that at least for some , if not most homosexuals, that pattern repeats itself.\"\n",
      "'Response':\"Non-sarcasm\"\n",
      "\n",
      "'Input': \"A tenth grade education? Why am I not surprised. That explains why you swallow this evo dung, because it makes you feel smart and enlightened. It is the most popular form of intellectual masturbation for the uninformed and pseudo intellectual today; not to mention the religion of the Natural Man. And here's a clue for you buddy, don't believe everything you read on the internet. Try using common sense before swallowing this tripe and if you want to exercise your common sense muscle, go back and reread all of my posts and try to answer all of my questions objectively. You know, those questions that you and every one of your compadres have completely ignored and not attempted to directly answer at all.\"\n",
      "'Response':\"Sarcasm\"\n",
      "\n",
      "'Input': \"I will stop quoting here. Don't want people to have too big a read. Actually ToE isn't all that random. To a certain degree yes. But Sexual Selection aka a part of the ToE. Dictates that when there is a benificial/attractive change. That change will be enhanced almost exponentially. Because the female of the species will be programmed to search for that and will carry the gene herself so will give it to her off spring. And the male will be more succesfull so produce more off spring. So no instant eyes or anything like that. I think that's what you were implying. Sorry for responding in Kronus's stead. I'm sure he can defend himself but I found it unjust the way you replied to his post and attacked it on foundations that you didn't have.\"\n",
      "'Response':\"Non-sarcasm\"\n",
      "\n",
      "'Input': \"oh yes liberal: anyone who disagrees with vor regardless of their political standing. you would call frist a liberal if he disagreed with you, hell you would even goldwater a liberal if he disagreed with you.  i'm going to mentally replace farfignewgin whenever you say liberal, after all, they have the same meaning in your context.  you can support the troops by disagreeing with any mission that is unncessary in terms of security and any mission that puts troops in unncessary danger. explain to me how you can support the troops by supporting a mission that doesn't help america and gets 1600 of them needlessly killed.\"\n",
      "'Response':\"Sarcasm\"\n",
      "\n",
      "'Input': \"jp: you keep spouting the same inaccuracy. i have already given you the cornell law schools definition and explanation of the impeachment process. do you need harvard and dukes as well? the house brought a resolution of impeachment. the senate denied it. the house resolution is similar to an indictment. the senate denial is similar to a not guilty verdict. your need to distort demeans you. really? who are you, carnack the magnificent? you can tell what would happen. richard nixon resigned and his offense was not as serious for the national security as the underlying offense is for libby. bottom line is you dont know what would happen. nobody does. but is does reveal that the only basis for you erroneous rhetoric is your speculation and distortion..\"\n",
      "'Response':\"Non-sarcasm\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_few_shot_examples = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    # if index == 3: # or index == 4:\n",
    "    #     formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    # if index == 4:\n",
    "    #     break\n",
    "\n",
    "# Display the result\n",
    "print(formatted_few_shot_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt, parse response and  generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the function to create the prompt\n",
    "def create_prompt(input, num_examples):\n",
    "\n",
    "    # messages = [system_prompt + formatted_few_shot_examples, f\"\\'Input\\':'{input}'\\n\\'Response\\':\"]\n",
    "    messages = f\"\"\"\n",
    "                {formatted_few_shot_examples}\n",
    "                \\'Input\\':'{input}'\n",
    "                \\'Response\\':\n",
    "    \"\"\"\n",
    "    # messages = [system_prompt, input]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def parse_response(response):\n",
    "\n",
    "    # print(response)\n",
    "    if len(response) > 0:        \n",
    "        if \"Non-sarcasm\" in response:\n",
    "            return \"0\"\n",
    "        elif \"Sarcasm\" in response:\n",
    "            return \"1\"\n",
    "        else:# If no label is found, return None\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 525/525 [31:17<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "def process_data(output_filepath):\n",
    "    # df = pd.read_csv(data_filepath)\n",
    "    df = test_df\n",
    "    # print(df)\n",
    "    # df = df[:5]\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    num_examples = 15 # number of shots in few-shot\n",
    "    # Loop over the DataFrame and pass the text to generate response\n",
    "    for index, row in tqdm(list(df.iterrows())):\n",
    "        # print(row)\n",
    "        prompt = create_prompt(row['Sentence'], num_examples)\n",
    "        # print(prompt)\n",
    "        generations = generate_aya(model, [prompt])\n",
    "        # print(generations[0])\n",
    "        generated_label = parse_response(generations[0])\n",
    "        # print(generated_label)\n",
    "\n",
    "        # # veracity, explanation = parse_response(model_response)\n",
    "        \n",
    "        results.append({\n",
    "            'Sentence': row['Sentence'],\n",
    "            'Label': row['Tag'],\n",
    "            'Response': generations[0],\n",
    "            'Gen_label': generated_label,\n",
    "            # 'Explanation': explanation\n",
    "        })\n",
    "        # break\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example file paths, replace with your actual paths\n",
    "output_filepath = '/data1/debajyoti/test/llms/data/humor'\n",
    "\n",
    "# Run the data processing\n",
    "result = process_data(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gen_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mera bhanja mujhe \"papa ka sala\" bulata hai......</td>\n",
       "      <td>0</td>\n",
       "      <td>To determine whether the 'Input' is sarcastic ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>To determine whether an 'Input' is sarcastic o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aur aap a0ni politics karne me vyast hai.. #Bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the context and tone, the final 'Resp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theek hai waha at least Janki ma ka mandir hai...</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the context and tone, the final 'Inpu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sir mujhe cricket acdemy join karna hai mai ka...</td>\n",
       "      <td>0</td>\n",
       "      <td>'Output': \"Sarcasm\"\\n\\nThe input is in Hindi a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>aaj bjp aur chadhi gang aise khus ho rahe hai ...</td>\n",
       "      <td>0</td>\n",
       "      <td>To determine whether an 'Input' is sarcastic o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>@SGanguly99 sir aapnio jodi aamar saath na den...</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the patterns and tone of the previous...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>#Irony: Pran ka pran chala gaya.. RIP Sher Khan!</td>\n",
       "      <td>1</td>\n",
       "      <td>To determine whether an 'Input' is sarcastic o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Ye bhi mat bhulo ki triple talaq ko ban lagane...</td>\n",
       "      <td>0</td>\n",
       "      <td>Based on the provided inputs and responses, he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>#ViruPanti @virendersehwag @cricketaakash DHON...</td>\n",
       "      <td>0</td>\n",
       "      <td>To determine whether an 'Input' is sarcastic o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>525 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Label  \\\n",
       "0    Mera bhanja mujhe \"papa ka sala\" bulata hai......      0   \n",
       "1    Tu sale TRIPLE TALAQ nd HALALA Ke baad ki sant...      0   \n",
       "2    aur aap a0ni politics karne me vyast hai.. #Bi...      0   \n",
       "3    Theek hai waha at least Janki ma ka mandir hai...      0   \n",
       "4    Sir mujhe cricket acdemy join karna hai mai ka...      0   \n",
       "..                                                 ...    ...   \n",
       "520  aaj bjp aur chadhi gang aise khus ho rahe hai ...      0   \n",
       "521  @SGanguly99 sir aapnio jodi aamar saath na den...      0   \n",
       "522   #Irony: Pran ka pran chala gaya.. RIP Sher Khan!      1   \n",
       "523  Ye bhi mat bhulo ki triple talaq ko ban lagane...      0   \n",
       "524  #ViruPanti @virendersehwag @cricketaakash DHON...      0   \n",
       "\n",
       "                                              Response Gen_label  \n",
       "0    To determine whether the 'Input' is sarcastic ...         1  \n",
       "1    To determine whether an 'Input' is sarcastic o...         0  \n",
       "2    Based on the context and tone, the final 'Resp...         1  \n",
       "3    Based on the context and tone, the final 'Inpu...         1  \n",
       "4    'Output': \"Sarcasm\"\\n\\nThe input is in Hindi a...         1  \n",
       "..                                                 ...       ...  \n",
       "520  To determine whether an 'Input' is sarcastic o...         1  \n",
       "521  Based on the patterns and tone of the previous...         1  \n",
       "522  To determine whether an 'Input' is sarcastic o...         1  \n",
       "523  Based on the provided inputs and responses, he...         1  \n",
       "524  To determine whether an 'Input' is sarcastic o...         0  \n",
       "\n",
       "[525 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
