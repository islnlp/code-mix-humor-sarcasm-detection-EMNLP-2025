{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/debajyoti/test/llms/envllm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = False \n",
    "cache_dir = \"/data1/debajyoti/test/llms/models\"\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Telugu-LLM-Labs/Indic-gemma-7b-finetuned-sft-Navarasa-2.0\",\n",
    "    cache_dir = cache_dir,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "input_prompt = \"\"\"\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "input_text = input_prompt.format(\n",
    "        \"\"\"You are a humor recognition assistant judging if an 'Input' is humorous or not. Dont give output anything else.\n",
    "    If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \n",
    "    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"\"\", # instruction\n",
    "        \"Chalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi chaltapic.twitter.com/bOLAEk0g4E\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "\n",
    "inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)\n",
    "response = tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<bos>\\n### Instruction:\\nYou are a humor recognition assistant judging if an 'Input' is humorous or not. Dont give output anything else.\\n    If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \\n    If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\\n\\n### Input:\\nChalo protocol pata chal gaya. Vice President agar Muslim na hote toh shayad kabhi pata hi nahi chaltapic.twitter.com/bOLAEk0g4E\\n\\n### Response:\\nNon-humor<eos>\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_text = input_prompt.format(\n",
    "#         \"\"\"You are a humor recognition assistant judging if an 'Input' is humorous or not. Dont give output anything else.\n",
    "#     If the 'Input' is humorous, you need to output your final 'Output' as 'Humor'. \n",
    "#     If the 'Input' is non-humorous, you need to output your final 'Output' as 'Non-humor'.\"\"\", # instruction\n",
    "#         \"What happens if Usain Bolt misses his bus? He waits for it at the next stop.\", # input\n",
    "#         \"\", # output - leave this blank for generation!\n",
    "#     )\n",
    "\n",
    "# inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "# outputs = model.generate(**inputs, max_new_tokens = 300, use_cache = True)\n",
    "# response = tokenizer.batch_decode(outputs)\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 2 takiye ki naukri main mera lakhon ka worl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Naam : Viv Richards\\nBaap ka naam : Master Di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sakshi Maharaj is BJP's Digvijaya Singh.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj @British_Airways ki toh lag gayi bhai.\\nHa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghanta development hoga! Saare paise to electi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hum to Aam Aadmi hain ji, woh Megalomaniac hai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Neend nahi aati hai raaton mein?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Ghar mein Bipasha Basu ki photo rakhne se bhoo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tu na ja mere baadshah ek waade ke liye, maa c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Tag\n",
       "0    Is 2 takiye ki naukri main mera lakhon ka worl...    0\n",
       "1    \"Naam : Viv Richards\\nBaap ka naam : Master Di...    1\n",
       "2             Sakshi Maharaj is BJP's Digvijaya Singh.    1\n",
       "3    Aaj @British_Airways ki toh lag gayi bhai.\\nHa...    1\n",
       "4    Ghanta development hoga! Saare paise to electi...    1\n",
       "..                                                 ...  ...\n",
       "291  Hum to Aam Aadmi hain ji, woh Megalomaniac hai...    1\n",
       "292                   Neend nahi aati hai raaton mein?    0\n",
       "293  Ghar mein Bipasha Basu ki photo rakhne se bhoo...    1\n",
       "294    Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V    0\n",
       "295  Tu na ja mere baadshah ek waade ke liye, maa c...    1\n",
       "\n",
       "[296 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_df_eng = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Humour_English(NEW).csv\")\n",
    "# train_df_eng = train_df_eng[:2000]\n",
    "# train_df_hin = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/1Humour_English(NEW).csv\")\n",
    "# train_df_hin = train_df_hin[:2000]\n",
    "# train_df = pd.concat([train_df_eng, train_df_hin], ignore_index=True)\n",
    "# train_df = train_df_hin\n",
    "train_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/train.csv\")\n",
    "val_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/val.csv\")\n",
    "test_df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/Dataset/splits/humor/test.csv\")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡•à‡§∞‡§æ‡§∂‡•Ç‡§ü ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§π‡•à‡§Ç‡•§‡§µ‡•á ‡§ñ‡•Å‡§≤‡•á ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§∏‡§¨‡§∏‡•á ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞‡•Ä, ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§•‡§æ...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‡§Ø‡§¶‡§ø ‡§Ø‡§π ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§π‡•à, ‡§§‡•ã ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡§π‡§æ‡§Ç...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§ú‡•â‡§ó‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø ‡§ï‡•Ä ‡§ó‡§§‡§ø ‡§∏‡•á ‡§ö‡§≤‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§ï‡•ç‡§Ø‡§æ ...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>‡§ú‡§¨ ‡§Ü‡§™‡§ï‡§æ ‡§ú‡•Ä‡§µ‡§® ‡§è‡§ï ‡§≤‡§æ‡§ñ ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§ø‡§ñ‡§∞ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à, ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>‡§Æ‡•á‡§∞‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ‡§ø‡§ï‡§æ ‡§®‡•á ‡§∏‡•ã‡§ö‡§æ ‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§è‡§ï ‡§Æ‡§∏‡•å‡§¶‡§æ ‡§π‡•à,...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§ê‡§∏‡•á ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§≤‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à ...</td>\n",
       "      <td>Humor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>‡§¨‡§∏ ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§∏‡§ø‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Ç, ‡§§‡•ã ‡§ï‡•ã‡§à ‡§õ‡•ã‡§∞ ‡§≤...</td>\n",
       "      <td>Non-humor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence        Tag\n",
       "0  ‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡•à‡§∞‡§æ‡§∂‡•Ç‡§ü ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§π‡•à‡§Ç‡•§‡§µ‡•á ‡§ñ‡•Å‡§≤‡•á ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§∏‡§¨‡§∏‡•á ...      Humor\n",
       "1  ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞‡•Ä, ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§•‡§æ...  Non-humor\n",
       "2  ‡§Ø‡§¶‡§ø ‡§Ø‡§π ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§π‡•à, ‡§§‡•ã ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡§π‡§æ‡§Ç...      Humor\n",
       "3  ‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§ú‡•â‡§ó‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø ‡§ï‡•Ä ‡§ó‡§§‡§ø ‡§∏‡•á ‡§ö‡§≤‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§ï‡•ç‡§Ø‡§æ ...  Non-humor\n",
       "4  ‡§ú‡§¨ ‡§Ü‡§™‡§ï‡§æ ‡§ú‡•Ä‡§µ‡§® ‡§è‡§ï ‡§≤‡§æ‡§ñ ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§ø‡§ñ‡§∞ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à, ...      Humor\n",
       "5  ‡§Æ‡•á‡§∞‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ‡§ø‡§ï‡§æ ‡§®‡•á ‡§∏‡•ã‡§ö‡§æ ‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§è‡§ï ‡§Æ‡§∏‡•å‡§¶‡§æ ‡§π‡•à,...  Non-humor\n",
       "6  ‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§ê‡§∏‡•á ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§≤‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à ...      Humor\n",
       "7  ‡§¨‡§∏ ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§∏‡§ø‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Ç, ‡§§‡•ã ‡§ï‡•ã‡§à ‡§õ‡•ã‡§∞ ‡§≤...  Non-humor"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/data1/debajyoti/code-mix-humor-sarcasm-detection/outputs/humor/few_shots/colbert_eng_llama.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': '‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡•à‡§∞‡§æ‡§∂‡•Ç‡§ü ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§π‡•à‡§Ç‡•§‡§µ‡•á ‡§ñ‡•Å‡§≤‡•á ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§‡§¨‡§∏ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§§‡§æ‡§∞ ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§∏‡§Ç‡§≤‡§ó‡•ç‡§® ‡§π‡•à‡§Ç‡•§'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞‡•Ä, ‡§∞‡§æ‡§ú‡§ï‡•Å‡§Æ‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§™‡§∞‡•ç‡§Ø‡§æ‡§™‡•ç‡§§ ‡§Ö‡§®‡•Å‡§≠‡§µ ‡§•‡§æ, ‡§Æ‡•á‡§Ç‡§¢‡§ï ‡§ï‡•Ä ‡§§‡§≤‡§æ‡§∂ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§Ø‡§¶‡§ø ‡§Ø‡§π ‡§™‡§∞‡•ç‡§Ø‡§ü‡§ï ‡§ï‡§æ ‡§Æ‡•å‡§∏‡§Æ ‡§π‡•à, ‡§§‡•ã ‡§Æ‡•Å‡§ù‡•á ‡§≤‡§æ‡§á‡§∏‡•á‡§Ç‡§∏ ‡§ï‡§π‡§æ‡§Ç ‡§Æ‡§ø‡§≤‡•á‡§ó‡§æ?'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§Ø‡§¶‡§ø ‡§ï‡•ã‡§à ‡§ú‡•â‡§ó‡§∞ ‡§ß‡•ç‡§µ‡§®‡§ø ‡§ï‡•Ä ‡§ó‡§§‡§ø ‡§∏‡•á ‡§ö‡§≤‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§ï‡•ç‡§Ø‡§æ ‡§µ‡§π ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§Ö‡§™‡§®‡•á ‡§µ‡•â‡§ï‡§Æ‡•à‡§® ‡§ï‡•ã ‡§∏‡•Å‡§® ‡§∏‡§ï‡§§‡§æ ‡§π‡•à?'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§ú‡§¨ ‡§Ü‡§™‡§ï‡§æ ‡§ú‡•Ä‡§µ‡§® ‡§è‡§ï ‡§≤‡§æ‡§ñ ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§ø‡§ñ‡§∞ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§ï‡•ã ‡§â‡§†‡§æ‡§è‡§Ç, ‡§ï‡•Å‡§õ ‡§ó‡•ã‡§Ç‡§¶ ‡§ï‡•ã ‡§™‡§ï‡§°‡§º‡•á‡§Ç, ‡§î‡§∞ ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§¨‡§®‡§æ‡§è‡§Ç‡•§'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§Æ‡•á‡§∞‡•Ä ‡§™‡•ç‡§∞‡•á‡§Æ‡§ø‡§ï‡§æ ‡§®‡•á ‡§∏‡•ã‡§ö‡§æ ‡§ï‡§ø ‡§Ø‡§π ‡§∏‡§ø‡§∞‡•ç‡§´ ‡§è‡§ï ‡§Æ‡§∏‡•å‡§¶‡§æ ‡§π‡•à, ‡§á‡§∏‡§≤‡§ø‡§è ‡§â‡§∏‡§®‡•á ‡§ï‡§ø‡§®‡§æ‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡•ç‡§ï‡•à‡§≤‡§™ ‡§ï‡§ø‡§Ø‡§æ ‡§î‡§∞ ‡§á‡§∏‡•á ‡§ï‡§™‡§ï‡•á‡§ï ‡§≤‡§æ‡§á‡§®‡§∞ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§á‡§∏‡•ç‡§§‡•á‡§Æ‡§æ‡§≤ ‡§ï‡§ø‡§Ø‡§æ‡•§'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§∏‡•Ä ‡§ê‡§∏‡•á ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ó‡§≤‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§π‡•à ‡§ú‡•ã ‡§≤‡§æ‡§®‡§§ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§'},\n",
       " {'role': 'assistant', 'content': 'Humor'},\n",
       " {'role': 'user',\n",
       "  'content': '‡§¨‡§∏ ‡§ú‡§¨ ‡§Æ‡•à‡§Ç ‡§∏‡§ø‡§∞‡•ã‡§Ç ‡§ï‡•ã ‡§™‡•Ç‡§∞‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•Ç‡§Ç, ‡§§‡•ã ‡§ï‡•ã‡§à ‡§õ‡•ã‡§∞ ‡§≤‡•á ‡§ú‡§æ‡§§‡§æ ‡§π‡•à‡•§'},\n",
       " {'role': 'assistant', 'content': 'Non-humor'}]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert dataframe to specified format\n",
    "formatted_few_shot_examples = []\n",
    "for _, row in df.iterrows():\n",
    "    formatted_few_shot_examples.append({'role': 'user', 'content': row['Sentence']})\n",
    "    formatted_few_shot_examples.append({'role': 'assistant', 'content': row['Tag']})\n",
    "    \n",
    "formatted_few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Input': \"‡§¶‡§ø‡§Æ‡§æ‡§ó ‡§™‡•à‡§∞‡§æ‡§∂‡•Ç‡§ü ‡§ï‡•Ä ‡§§‡§∞‡§π ‡§π‡•à‡§Ç‡•§‡§µ‡•á ‡§ñ‡•Å‡§≤‡•á ‡§π‡•ã‡§®‡•á ‡§™‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§Ö‡§ö‡•ç‡§õ‡§æ ‡§ï‡§æ‡§Æ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç‡•§‡§¨‡§∏ ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§§‡§æ‡§∞ ‡§Ö‡§≠‡•Ä ‡§≠‡•Ä ‡§∏‡§Ç‡§≤‡§ó‡•ç‡§® ‡§π‡•à‡§Ç‡•§\"\n",
      "'Response':\"Humor\"\n",
      "\n",
      "'Input': \"‡§ú‡§¨ ‡§Ü‡§™‡§ï‡§æ ‡§ú‡•Ä‡§µ‡§® ‡§è‡§ï ‡§≤‡§æ‡§ñ ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§¨‡§ø‡§ñ‡§∞ ‡§ú‡§æ‡§§‡§æ ‡§π‡•à, ‡§§‡•ã ‡§ü‡•Å‡§ï‡§°‡§º‡•ã‡§Ç ‡§ï‡•ã ‡§â‡§†‡§æ‡§è‡§Ç, ‡§ï‡•Å‡§õ ‡§ó‡•ã‡§Ç‡§¶ ‡§ï‡•ã ‡§™‡§ï‡§°‡§º‡•á‡§Ç, ‡§î‡§∞ ‡§è‡§ï ‡§®‡§Ø‡§æ ‡§¨‡§®‡§æ‡§è‡§Ç‡•§\"\n",
      "'Response':\"Humor\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "formatted_few_shot_examples = \"\"\n",
    "for index, row in df.iterrows():\n",
    "    if index == 0 or index == 4:\n",
    "        formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    # formatted_few_shot_examples += f\"\"\"'Input': \"{row['Sentence']}\"\\n'Response':\"{row['Tag']}\"\\n\\n\"\"\"\n",
    "    # if index == 1:\n",
    "    #     break\n",
    "\n",
    "# Display the result\n",
    "print(formatted_few_shot_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompt, parse response and  generate response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import re\n",
    "import json\n",
    "\n",
    "# Define the function to create the prompt\n",
    "def create_prompt(input, num_examples):\n",
    "\n",
    "    # System prompt \n",
    "    system_prompt = \"\"\"You are a humor recognition assistant judging if an 'Input' is sarcastic or not. \n",
    "        If the 'Input' is sarcastic, you need to give your final 'Output' as \"Humor\". \n",
    "        If the 'Input' is non-sarcastic, you need to give your final 'Output' as \"Non-humor\". Dont output anything else. \"\"\"\n",
    "\n",
    "    messages = [system_prompt + formatted_few_shot_examples, input]\n",
    "    # messages = [system_prompt, input]\n",
    "\n",
    "    return messages\n",
    "\n",
    "def parse_response(response):\n",
    "    \"\"\"\n",
    "    Extracts the classification label and explanation from the model-generated response,\n",
    "    starting from the line containing the final \"Answer:\".\n",
    "\n",
    "    Args:\n",
    "        response (str): The response generated by the model.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the classification label (\"Humor\" or \"Non-humor\") \n",
    "               and the explanation text.\n",
    "    \"\"\"\n",
    "    # print(response)\n",
    "    if len(response) > 0:        \n",
    "        if \"Non-humor\" in response:\n",
    "            return \"0\"\n",
    "        elif \"Humor\" in response:\n",
    "            return \"1\"\n",
    "        else:# If no label is found, return None\n",
    "            return None\n",
    "\n",
    "def generate_responses(prompt):\n",
    "    \n",
    "    input_prompt = \"\"\"\n",
    "    ### Instruction:\n",
    "    {}\n",
    "\n",
    "    ### Input:\n",
    "    {}\n",
    "\n",
    "    ### Response:\n",
    "    {}\"\"\"\n",
    "\n",
    "    input_text = input_prompt.format(\n",
    "            f\"\"\"{prompt[0]}\"\"\", # instruction\n",
    "            f\"{prompt[1]}\", # input\n",
    "            \"\", # output - leave this blank for generation!\n",
    "        )\n",
    "\n",
    "    inputs = tokenizer([input_text], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 400, use_cache = True)\n",
    "    response = tokenizer.batch_decode(outputs)\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/296 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 296/296 [01:11<00:00,  4.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_data(output_filepath):\n",
    "    # df = pd.read_csv(data_filepath)\n",
    "    df = test_df\n",
    "    # df = df[:5]\n",
    "    \n",
    "    \n",
    "    results = []\n",
    "    num_examples = 15 # number of shots in few-shot\n",
    "    # Loop over the DataFrame and pass the text to generate response\n",
    "    for index, row in tqdm(list(df.iterrows())):\n",
    "        prompt = create_prompt(row['Sentence'], num_examples)\n",
    "        model_response = generate_responses(prompt)\n",
    "        # print(model_response)\n",
    "        generated_label = parse_response(model_response)\n",
    "\n",
    "        # veracity, explanation = parse_response(model_response)\n",
    "        \n",
    "        results.append({\n",
    "            'Sentence': row['Sentence'],\n",
    "            'Label': row['Tag'],\n",
    "            'Response': model_response,\n",
    "            'Gen_label': generated_label,\n",
    "            # 'Explanation': explanation\n",
    "        })\n",
    "        # break\n",
    "    \n",
    "    results = pd.DataFrame(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example file paths, replace with your actual paths\n",
    "output_filepath = '/data1/debajyoti/test/llms/data/humor'\n",
    "\n",
    "# Run the data processing\n",
    "result = process_data(output_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Label</th>\n",
       "      <th>Response</th>\n",
       "      <th>Gen_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is 2 takiye ki naukri main mera lakhon ka worl...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Naam : Viv Richards\\nBaap ka naam : Master Di...</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sakshi Maharaj is BJP's Digvijaya Singh.</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaj @British_Airways ki toh lag gayi bhai.\\nHa...</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ghanta development hoga! Saare paise to electi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Hum to Aam Aadmi hain ji, woh Megalomaniac hai...</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Neend nahi aati hai raaton mein?</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>Ghar mein Bipasha Basu ki photo rakhne se bhoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V</td>\n",
       "      <td>0</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Tu na ja mere baadshah ek waade ke liye, maa c...</td>\n",
       "      <td>1</td>\n",
       "      <td>[&lt;bos&gt;\\n    ### Instruction:\\n    You are a hu...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Label  \\\n",
       "0    Is 2 takiye ki naukri main mera lakhon ka worl...      0   \n",
       "1    \"Naam : Viv Richards\\nBaap ka naam : Master Di...      1   \n",
       "2             Sakshi Maharaj is BJP's Digvijaya Singh.      1   \n",
       "3    Aaj @British_Airways ki toh lag gayi bhai.\\nHa...      1   \n",
       "4    Ghanta development hoga! Saare paise to electi...      1   \n",
       "..                                                 ...    ...   \n",
       "291  Hum to Aam Aadmi hain ji, woh Megalomaniac hai...      1   \n",
       "292                   Neend nahi aati hai raaton mein?      0   \n",
       "293  Ghar mein Bipasha Basu ki photo rakhne se bhoo...      1   \n",
       "294    Aur dikhao aur dikhaopic.twitter.com/Ij4R6xNg9V      0   \n",
       "295  Tu na ja mere baadshah ek waade ke liye, maa c...      1   \n",
       "\n",
       "                                              Response Gen_label  \n",
       "0    [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "1    [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "2    [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "3    [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "4    [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "..                                                 ...       ...  \n",
       "291  [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "292  [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "293  [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "294  [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "295  [<bos>\\n    ### Instruction:\\n    You are a hu...      None  \n",
       "\n",
       "[296 rows x 4 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Label: Humor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1120943/869760653.py:21: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n",
      "  @validator('output_label', pre=True, always=True)\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "import re\n",
    "\n",
    "class ModelResponse(BaseModel):\n",
    "    instruction: str\n",
    "    input_text: str\n",
    "    output_label: str\n",
    "\n",
    "    # @validator('instruction', pre=True, always=True)\n",
    "    # def extract_instruction(cls, value, values):\n",
    "    #     # Extract the Instruction part\n",
    "    #     match = re.search(r'### Instruction:\\n(.+?)\\n\\n### Input:', value, re.DOTALL)\n",
    "    #     return match.group(1).strip() if match else \"\"\n",
    "\n",
    "    # @validator('input_text', pre=True, always=True)\n",
    "    # def extract_input_text(cls, value, values):\n",
    "    #     # Extract the Input part\n",
    "    #     match = re.search(r'### Input:\\n(.+?)\\n\\n### Response:', value, re.DOTALL)\n",
    "    #     return match.group(1).strip() if match else \"\"\n",
    "\n",
    "    @validator('output_label', pre=True, always=True)\n",
    "    def extract_output_label(cls, value, values):\n",
    "        # Extract the Response part\n",
    "        match = re.search(r'### Response:\\n(.+?)<eos>', value, re.DOTALL)\n",
    "        return match.group(1).strip() if match else \"\"\n",
    "\n",
    "# Example usage\n",
    "response_text = (\n",
    "    \"<bos>\\n### Instruction:\\nYou are a humor recognition assistant judging if an 'Input' \"\n",
    "    \"is humorous or not. Dont give output anything else.\\n    If the 'Input' is humorous, \"\n",
    "    \"you need to output your final 'Output' as 'Humor'. \\n    If the 'Input' is non-humorous, \"\n",
    "    \"you need to output your final 'Output' as 'Non-humor'.\\n\\n### Input:\\nWhat happens if Usain Bolt \"\n",
    "    \"misses his bus? He waits for it at the next stop.\\n\\n### Response:\\nHumor<eos>\"\n",
    ")\n",
    "\n",
    "# Create ModelResponse object\n",
    "parsed_response = ModelResponse(instruction=response_text, input_text=response_text, output_label=response_text)\n",
    "\n",
    "# Access parsed fields\n",
    "# print(\"Instruction:\", parsed_response.instruction)\n",
    "# print(\"Input Text:\", parsed_response.input_text)\n",
    "print(\"Output Label:\", parsed_response.output_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tqdm(list(result.iterrows())):\n",
    "    parsed_response = ModelResponse(instruction=row['Response'][0], input_text=row['Response'][0], output_label=row['Response'][0])\n",
    "\n",
    "    # Access parsed fields\n",
    "    print(\"Output Label:\", parsed_response.output_label)\n",
    "    result['Gen_label'][index] = parsed_response.output_label\n",
    "    print(result['Gen_label'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Gen_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the Gen_label column values\n",
    "result['Gen_label'] = result['Gen_label'].str.replace(r'\\W', '', regex=True).str.lower()\n",
    "\n",
    "# Map the standardized labels to the final desired labels\n",
    "result['Gen_label'] = result['Gen_label'].map({\n",
    "    'nonhumor': 'Non-humor',\n",
    "    'humor': 'Humor'\n",
    "})\n",
    "\n",
    "# Check the updated value counts\n",
    "print(result['Gen_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map string labels to integers\n",
    "label_mapping = {'Non-humor': 0, 'Humor': 1}\n",
    "new_result['Gen_label'] = new_result['Gen_label'].map(label_mapping)\n",
    "\n",
    "# Check the result\n",
    "print(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = list(map(int, new_result['Label']))\n",
    "y_pred = list(map(int, new_result['Gen_label']))\n",
    "print(classification_report(y_true, y_pred, digits=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
